{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I'm not sure why, but my fancy pipelines seem to only get <0.40\n",
    "Let's start with https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough, who got at least 0.42 in the notebook, then see where I went wrong. I'll import my existing tools when relevant but otherwise do all the work in the notebook for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools for developing code\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# Add library to path \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from lib.model import kfold, f1_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dependency</th>\n",
       "      <th>edjefa</th>\n",
       "      <th>edjefe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9557.000000</td>\n",
       "      <td>9557.000000</td>\n",
       "      <td>9557.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.149550</td>\n",
       "      <td>2.896830</td>\n",
       "      <td>5.096788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.605993</td>\n",
       "      <td>4.612056</td>\n",
       "      <td>5.246513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dependency       edjefa       edjefe\n",
       "count  9557.000000  9557.000000  9557.000000\n",
       "mean      1.149550     2.896830     5.096788\n",
       "std       1.605993     4.612056     5.246513\n",
       "min       0.000000     0.000000     0.000000\n",
       "25%       0.333333     0.000000     0.000000\n",
       "50%       0.666667     0.000000     6.000000\n",
       "75%       1.333333     6.000000     9.000000\n",
       "max       8.000000    21.000000    21.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\"yes\": 1, \"no\": 0}\n",
    "\n",
    "# Apply same operation to both train and test\n",
    "for df in [train, test]:\n",
    "    # Fill in the values with the correct mapping\n",
    "    df['dependency'] = df['dependency'].replace(mapping).astype(np.float64)\n",
    "    df['edjefa'] = df['edjefa'].replace(mapping).astype(np.float64)\n",
    "    df['edjefe'] = df['edjefe'].replace(mapping).astype(np.float64)\n",
    "\n",
    "train[['dependency', 'edjefa', 'edjefe']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add null Target column to test\n",
    "test['Target'] = np.nan\n",
    "data = train.append(test, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct labels for households with multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 85 households where the family members do not all have the same target.\n"
     ]
    }
   ],
   "source": [
    "# Groupby the household and figure out the number of unique values\n",
    "all_equal = train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n",
    "\n",
    "# Households where targets are not all equal\n",
    "not_equal = all_equal[all_equal != True]\n",
    "print('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 households where the family members do not all have the same target.\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each household\n",
    "for household in not_equal.index:\n",
    "    # Find the correct label (for the head of household)\n",
    "    true_target = int(train[(train['idhogar'] == household) & (train['parentesco1'] == 1.0)]['Target'])\n",
    "    \n",
    "    # Set the correct label for all members in the household\n",
    "    train.loc[train['idhogar'] == household, 'Target'] = true_target\n",
    "    \n",
    "    \n",
    "# Groupby the household and figure out the number of unique values\n",
    "all_equal = train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n",
    "\n",
    "# Households where targets are not all equal\n",
    "not_equal = all_equal[all_equal != True]\n",
    "print('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rez_esc</th>\n",
       "      <td>27581</td>\n",
       "      <td>0.825457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v18q1</th>\n",
       "      <td>25468</td>\n",
       "      <td>0.762218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v2a1</th>\n",
       "      <td>24263</td>\n",
       "      <td>0.726154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQBmeaned</th>\n",
       "      <td>36</td>\n",
       "      <td>0.001077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaneduc</th>\n",
       "      <td>36</td>\n",
       "      <td>0.001077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_adul</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              total   percent\n",
       "rez_esc       27581  0.825457\n",
       "v18q1         25468  0.762218\n",
       "v2a1          24263  0.726154\n",
       "SQBmeaned        36  0.001077\n",
       "meaneduc         36  0.001077\n",
       "hogar_adul        0  0.000000\n",
       "parentesco10      0  0.000000\n",
       "parentesco11      0  0.000000\n",
       "parentesco12      0  0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of missing in each column\n",
    "missing = pd.DataFrame(data.isnull().sum()).rename(columns = {0: 'total'})\n",
    "\n",
    "# Create a percentage missing\n",
    "missing['percent'] = missing['total'] / len(data)\n",
    "\n",
    "missing.sort_values('percent', ascending = False).head(10).drop('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing num tablets means you don't have one\n",
    "data['v18q1'] = data['v18q1'].fillna(0)\n",
    "\n",
    "# Fill in households that own the house with 0 rent payment\n",
    "data.loc[(data['tipovivi1'] == 1), 'v2a1'] = 0\n",
    "\n",
    "# Create missing rent payment column\n",
    "data['v2a1-missing'] = data['v2a1'].isnull()\n",
    "\n",
    "data['v2a1-missing'].value_counts()\n",
    "\n",
    "# If individual is over 19 or younger than 7 and missing years behind, set it to 0\n",
    "data.loc[((data['age'] > 19) | (data['age'] < 7)) & (data['rez_esc'].isnull()), 'rez_esc'] = 0\n",
    "\n",
    "# Add a flag for those between 7 and 19 with a missing value\n",
    "data['rez_esc-missing'] = data['rez_esc'].isnull()\n",
    "\n",
    "data.loc[data['rez_esc'] > 5, 'rez_esc'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no repeats:  True\n",
      "We covered every variable:  True\n"
     ]
    }
   ],
   "source": [
    "id_ = ['Id', 'idhogar', 'Target']\n",
    "\n",
    "ind_bool = ['v18q', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', \n",
    "            'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "            'parentesco1', 'parentesco2',  'parentesco3', 'parentesco4', 'parentesco5', \n",
    "            'parentesco6', 'parentesco7', 'parentesco8',  'parentesco9', 'parentesco10', \n",
    "            'parentesco11', 'parentesco12', 'instlevel1', 'instlevel2', 'instlevel3', \n",
    "            'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', \n",
    "            'instlevel9', 'mobilephone', 'rez_esc-missing']\n",
    "\n",
    "ind_ordered = ['rez_esc', 'escolari', 'age']\n",
    "\n",
    "hh_bool = ['hacdor', 'hacapo', 'v14a', 'refrig', 'paredblolad', 'paredzocalo', \n",
    "           'paredpreb','pisocemento', 'pareddes', 'paredmad',\n",
    "           'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisoother', \n",
    "           'pisonatur', 'pisonotiene', 'pisomadera',\n",
    "           'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', \n",
    "           'abastaguadentro', 'abastaguafuera', 'abastaguano',\n",
    "            'public', 'planpri', 'noelec', 'coopele', 'sanitario1', \n",
    "           'sanitario2', 'sanitario3', 'sanitario5',   'sanitario6',\n",
    "           'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', \n",
    "           'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', \n",
    "           'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3',\n",
    "           'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', \n",
    "           'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', \n",
    "           'computer', 'television', 'lugar1', 'lugar2', 'lugar3',\n",
    "           'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'v2a1-missing']\n",
    "\n",
    "hh_ordered = [ 'rooms', 'r4h1', 'r4h2', 'r4h3', 'r4m1','r4m2','r4m3', 'r4t1',  'r4t2', \n",
    "              'r4t3', 'v18q1', 'tamhog','tamviv','hhsize','hogar_nin',\n",
    "              'hogar_adul','hogar_mayor','hogar_total',  'bedrooms', 'qmobilephone']\n",
    "\n",
    "hh_cont = ['v2a1', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'overcrowding']\n",
    "\n",
    "sqr_ = ['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', \n",
    "        'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq']\n",
    "\n",
    "x = ind_bool + ind_ordered + id_ + hh_bool + hh_ordered + hh_cont + sqr_\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print('There are no repeats: ', np.all(np.array(list(Counter(x).values())) == 1))\n",
    "print('We covered every variable: ', len(x) == data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10307, 99)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove squared variables\n",
    "data = data.drop(columns = sqr_)\n",
    "\n",
    "heads = data.loc[data['parentesco1'] == 1, :]\n",
    "heads = heads[id_ + hh_bool + hh_cont + hh_ordered]\n",
    "heads.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redundant Household Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coopele', 'area2', 'tamhog', 'hhsize', 'hogar_total']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = heads.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.95)]\n",
    "\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = heads.drop(columns = ['tamhog', 'hogar_total', 'r4t3'])\n",
    "\n",
    "heads['hhsize-diff'] = heads['tamviv'] - heads['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec = []\n",
    "\n",
    "# Assign values\n",
    "for i, row in heads.iterrows():\n",
    "    if row['noelec'] == 1:\n",
    "        elec.append(0)\n",
    "    elif row['coopele'] == 1:\n",
    "        elec.append(1)\n",
    "    elif row['public'] == 1:\n",
    "        elec.append(2)\n",
    "    elif row['planpri'] == 1:\n",
    "        elec.append(3)\n",
    "    else:\n",
    "        elec.append(np.nan)\n",
    "        \n",
    "# Record the new variable and missing flag\n",
    "heads['elec'] = elec\n",
    "heads['elec-missing'] = heads['elec'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = heads.drop(columns = 'area2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wall ordinal variable\n",
    "heads['walls'] = np.argmax(np.array(heads[['epared1', 'epared2', 'epared3']]),\n",
    "                           axis = 1)\n",
    "\n",
    "# Roof ordinal variable\n",
    "heads['roof'] = np.argmax(np.array(heads[['etecho1', 'etecho2', 'etecho3']]),\n",
    "                           axis = 1)\n",
    "heads = heads.drop(columns = ['etecho1', 'etecho2', 'etecho3'])\n",
    "\n",
    "# Floor ordinal variable\n",
    "heads['floor'] = np.argmax(np.array(heads[['eviv1', 'eviv2', 'eviv3']]),\n",
    "                           axis = 1)\n",
    "\n",
    "# Create new feature\n",
    "heads['walls+roof+floor'] = heads['walls'] + heads['roof'] + heads['floor']\n",
    "\n",
    "\n",
    "# No toilet, no electricity, no floor, no water service, no ceiling\n",
    "heads['warning'] = 1 * (heads['sanitario1'] + \n",
    "                         (heads['elec'] == 0) + \n",
    "                         heads['pisonotiene'] + \n",
    "                         heads['abastaguano'] + \n",
    "                         (heads['cielorazo'] == 0))\n",
    "\n",
    "# Owns a refrigerator, computer, tablet, and television\n",
    "heads['bonus'] = 1 * (heads['refrig'] + \n",
    "                      heads['computer'] + \n",
    "                      (heads['v18q1'] > 0) + \n",
    "                      heads['television'])\n",
    "\n",
    "heads['phones-per-capita'] = heads['qmobilephone'] / heads['tamviv']\n",
    "heads['tablets-per-capita'] = heads['v18q1'] / heads['tamviv']\n",
    "heads['rooms-per-capita'] = heads['rooms'] / heads['tamviv']\n",
    "heads['rent-per-capita'] = heads['v2a1'] / heads['tamviv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_feats = list(heads.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process individual-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33413, 40)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = data[id_ + ind_bool + ind_ordered]\n",
    "ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = ind.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.95)]\n",
    "\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = ind.drop(columns = 'male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind['inst'] = np.argmax(np.array(ind[[c for c in ind if c.startswith('instl')]]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33413, 40)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    33413.000000\n",
       "mean         1.214886\n",
       "std          0.462567\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max          2.000000\n",
       "Name: tech, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind['escolari/age'] = ind['escolari'] / ind['age']\n",
    "\n",
    "ind['inst/age'] = ind['inst'] / ind['age']\n",
    "ind['tech'] = ind['v18q'] + ind['mobilephone']\n",
    "ind['tech'].describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">v18q</th>\n",
       "      <th colspan=\"4\" halign=\"left\">dis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">inst/age</th>\n",
       "      <th colspan=\"6\" halign=\"left\">tech</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>std</th>\n",
       "      <th>range_</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>std</th>\n",
       "      <th>range_</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>std</th>\n",
       "      <th>range_</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idhogar</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000a08204</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.139775</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000bce7c4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011785</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001845fb0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511959</td>\n",
       "      <td>4</td>\n",
       "      <td>0.060123</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001ff74ca</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003123ec2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213768</td>\n",
       "      <td>4</td>\n",
       "      <td>0.064636</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          v18q                           dis                ...    inst/age  \\\n",
       "           min max sum count  std range_ min max sum count  ...         sum   \n",
       "idhogar                                                     ...               \n",
       "000a08204    1   1   3     3  0.0      0   0   0   0     3  ...    0.483333   \n",
       "000bce7c4    0   0   0     2  0.0      0   0   1   1     2  ...    0.016667   \n",
       "001845fb0    0   0   0     4  0.0      0   0   0   0     4  ...    0.511959   \n",
       "001ff74ca    1   1   2     2  0.0      0   0   0   0     2  ...    0.184211   \n",
       "003123ec2    0   0   0     4  0.0      0   0   0   0     4  ...    0.213768   \n",
       "\n",
       "                                    tech                            \n",
       "          count       std    range_  min max sum count  std range_  \n",
       "idhogar                                                             \n",
       "000a08204     3  0.139775  0.250000    2   2   6     3  0.0      0  \n",
       "000bce7c4     2  0.011785  0.016667    1   1   2     2  0.0      0  \n",
       "001845fb0     4  0.060123  0.128205    1   1   4     4  0.0      0  \n",
       "001ff74ca     1       NaN  0.000000    2   2   4     2  0.0      0  \n",
       "003123ec2     4  0.064636  0.130435    1   1   4     4  0.0      0  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define custom function\n",
    "range_ = lambda x: x.max() - x.min()\n",
    "range_.__name__ = 'range_'\n",
    "\n",
    "# Group and aggregate\n",
    "ind_agg = ind.drop(columns = 'Target').groupby('idhogar').agg(['min', 'max', 'sum', 'count', 'std', range_])\n",
    "ind_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v18q-min</th>\n",
       "      <th>v18q-max</th>\n",
       "      <th>v18q-sum</th>\n",
       "      <th>v18q-count</th>\n",
       "      <th>v18q-std</th>\n",
       "      <th>v18q-range_</th>\n",
       "      <th>dis-min</th>\n",
       "      <th>dis-max</th>\n",
       "      <th>dis-sum</th>\n",
       "      <th>dis-count</th>\n",
       "      <th>...</th>\n",
       "      <th>inst/age-sum</th>\n",
       "      <th>inst/age-count</th>\n",
       "      <th>inst/age-std</th>\n",
       "      <th>inst/age-range_</th>\n",
       "      <th>tech-min</th>\n",
       "      <th>tech-max</th>\n",
       "      <th>tech-sum</th>\n",
       "      <th>tech-count</th>\n",
       "      <th>tech-std</th>\n",
       "      <th>tech-range_</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idhogar</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000a08204</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.139775</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000bce7c4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011785</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001845fb0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511959</td>\n",
       "      <td>4</td>\n",
       "      <td>0.060123</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001ff74ca</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003123ec2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213768</td>\n",
       "      <td>4</td>\n",
       "      <td>0.064636</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           v18q-min  v18q-max  v18q-sum  v18q-count  v18q-std  v18q-range_  \\\n",
       "idhogar                                                                      \n",
       "000a08204         1         1         3           3       0.0            0   \n",
       "000bce7c4         0         0         0           2       0.0            0   \n",
       "001845fb0         0         0         0           4       0.0            0   \n",
       "001ff74ca         1         1         2           2       0.0            0   \n",
       "003123ec2         0         0         0           4       0.0            0   \n",
       "\n",
       "           dis-min  dis-max  dis-sum  dis-count     ...       inst/age-sum  \\\n",
       "idhogar                                             ...                      \n",
       "000a08204        0        0        0          3     ...           0.483333   \n",
       "000bce7c4        0        1        1          2     ...           0.016667   \n",
       "001845fb0        0        0        0          4     ...           0.511959   \n",
       "001ff74ca        0        0        0          2     ...           0.184211   \n",
       "003123ec2        0        0        0          4     ...           0.213768   \n",
       "\n",
       "           inst/age-count  inst/age-std  inst/age-range_  tech-min  tech-max  \\\n",
       "idhogar                                                                        \n",
       "000a08204               3      0.139775         0.250000         2         2   \n",
       "000bce7c4               2      0.011785         0.016667         1         1   \n",
       "001845fb0               4      0.060123         0.128205         1         1   \n",
       "001ff74ca               1           NaN         0.000000         2         2   \n",
       "003123ec2               4      0.064636         0.130435         1         1   \n",
       "\n",
       "           tech-sum  tech-count  tech-std  tech-range_  \n",
       "idhogar                                                 \n",
       "000a08204         6           3       0.0            0  \n",
       "000bce7c4         2           2       0.0            0  \n",
       "001845fb0         4           4       0.0            0  \n",
       "001ff74ca         4           2       0.0            0  \n",
       "003123ec2         4           4       0.0            0  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns\n",
    "new_col = []\n",
    "for c in ind_agg.columns.levels[0]:\n",
    "    for stat in ind_agg.columns.levels[1]:\n",
    "        new_col.append(f'{c}-{stat}')\n",
    "        \n",
    "ind_agg.columns = new_col\n",
    "ind_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 111 correlated columns to remove.\n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = ind_agg.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.95)]\n",
    "\n",
    "print(f'There are {len(to_drop)} correlated columns to remove.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final features shape:  (10307, 228)\n"
     ]
    }
   ],
   "source": [
    "ind_agg = ind_agg.drop(columns = to_drop)\n",
    "ind_feats = list(ind_agg.columns)\n",
    "\n",
    "# Merge on the household id\n",
    "final = heads.merge(ind_agg, on = 'idhogar', how = 'left')\n",
    "\n",
    "print('Final features shape: ', final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female-head  Target\n",
       "0            4.0       0.682873\n",
       "             2.0       0.136464\n",
       "             3.0       0.123204\n",
       "             1.0       0.057459\n",
       "1            4.0       0.617369\n",
       "             2.0       0.167670\n",
       "             3.0       0.113500\n",
       "             1.0       0.101462\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_gender = ind.loc[ind['parentesco1'] == 1, ['idhogar', 'female']]\n",
    "final = final.merge(head_gender, on = 'idhogar', how = 'left').rename(columns = {'female': 'female-head'})\n",
    "final.groupby('female-head')['Target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom scorer for cross validation\n",
    "scorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for training\n",
    "train_labels = np.array(list(final[final['Target'].notnull()]['Target'].astype(np.uint8)))\n",
    "\n",
    "# Extract the training data\n",
    "train_set = final[final['Target'].notnull()].drop(columns = ['Id', 'idhogar', 'Target'])\n",
    "test_set = final[final['Target'].isnull()].drop(columns = ['Id', 'idhogar', 'Target'])\n",
    "\n",
    "# Submission base which is used for making submissions to the competition\n",
    "submission_base = test[['Id', 'idhogar']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_set.columns)\n",
    "\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)\n",
    "test_set = pipeline.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Fold Cross Validation F1 Score = 0.3425 with std = 0.0322\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=10, \n",
    "                               n_jobs = -1)\n",
    "# 10 fold cross validation\n",
    "cv_score = cross_val_score(model, train_set, train_labels, cv = 10, scoring = scorer)\n",
    "\n",
    "print(f'10 Fold Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hacdor</td>\n",
       "      <td>0.000643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hacapo</td>\n",
       "      <td>0.000283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v14a</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>refrig</td>\n",
       "      <td>0.001798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paredblolad</td>\n",
       "      <td>0.006024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0       hacdor    0.000643\n",
       "1       hacapo    0.000283\n",
       "2         v14a    0.000460\n",
       "3       refrig    0.001798\n",
       "4  paredblolad    0.006024"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_labels)\n",
    "\n",
    "# Feature importances into a dataframe\n",
    "feature_importances = pd.DataFrame({'feature': features, 'importance': model.feature_importances_})\n",
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coopele', 'elec', 'v18q-count', 'female-sum']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.DataFrame(train_set, columns = features)\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = train_set.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.95)]\n",
    "\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2973, 222)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = train_set.drop(columns = to_drop)\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.DataFrame(test_set, columns = features)\n",
    "train_set, test_set = train_set.align(test_set, axis = 1, join = 'inner')\n",
    "features = list(train_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Create a model for feature selection\n",
    "estimator = RandomForestClassifier(random_state = 10, n_estimators = 100,  n_jobs = -1)\n",
    "\n",
    "# Create the object\n",
    "selector = RFECV(estimator, step = 1, cv = 3, scoring= scorer, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "selector.fit(train_set, train_labels)\n",
    "\n",
    "plt.plot(selector.grid_scores_);\n",
    "\n",
    "plt.xlabel('Number of Features'); plt.ylabel('Macro F1 Score'); plt.title('Feature Selection Scores');\n",
    "selector.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>r4h2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>estadocivil7-std</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>estadocivil7-sum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>escolari-sum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>escolari-max</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>instlevel4-std</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>female-std</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>dis-sum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>instlevel8-sum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  rank\n",
       "73               r4h2     1\n",
       "130  estadocivil7-std     1\n",
       "129  estadocivil7-sum     1\n",
       "198      escolari-sum     1\n",
       "197      escolari-max     1\n",
       "86           bedrooms     1\n",
       "177    instlevel4-std     1\n",
       "109        female-std     1\n",
       "106           dis-sum     1\n",
       "187    instlevel8-sum     1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings = pd.DataFrame({'feature': list(train_set.columns), 'rank': list(selector.ranking_)}).sort_values('rank')\n",
    "rankings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selected = selector.transform(train_set)\n",
    "test_selected = selector.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to dataframe\n",
    "selected_features = train_set.columns[np.where(selector.ranking_==1)]\n",
    "train_selected = pd.DataFrame(train_selected, columns = selected_features)\n",
    "test_selected = pd.DataFrame(test_selected, columns = selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upgrading Our Model: Gradient Boosting Machine\n",
    "After using the Random Forest and getting decent scores, it's time to step up and use the gradient boosting machine. If you spend any time on Kaggle, you'll notice that the Gradient Boosting Machine (GBM) wins a high percentage of competitions where the data is structured (in tables) and the datasets are not that large (less than a million observations).\n",
    "\n",
    "I won't go too much into the details here, but instead will focus on the implementation. We'll use the GBM in LightGBM, although there are also options in Scikit-Learn, XGBOOST, and CatBoost. The first set of hyperparameters we'll use were based on those I've found have worked well for other problems.\n",
    "\n",
    "Choosing Number of Estimators with Early Stopping\n",
    "To choose the number of estimators (the number of decision trees in the ensemble, called n_estimators or num_boost_rounds), we'll use early stopping with 5-fold cross validation. This will keep adding estimators until the performance as measured by the Macro F1 Score has not increased for 100 training rounds. To use this metric, we'll have to define a custom metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1_score(labels, predictions):\n",
    "    # Reshape the predictions as needed\n",
    "    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n",
    "    \n",
    "    metric_value = f1_score(labels, predictions, average = 'macro')\n",
    "    \n",
    "    # Return is name, value, is_higher_better\n",
    "    return 'macro_f1', metric_value, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from IPython.display import display\n",
    "\n",
    "def model_gbm(features, labels, test_features, test_ids, \n",
    "              nfolds = 5, return_preds = False, hyp = None):\n",
    "    \"\"\"Model using the GBM and cross validation.\n",
    "       Trains with early stopping on each fold.\n",
    "       Hyperparameters probably need to be tuned.\"\"\"\n",
    "    \n",
    "    feature_names = list(features.columns)\n",
    "\n",
    "    # Option for user specified hyperparameters\n",
    "    if hyp is not None:\n",
    "        # Using early stopping so do not need number of esimators\n",
    "        if 'n_estimators' in hyp:\n",
    "            del hyp['n_estimators']\n",
    "        params = hyp\n",
    "    \n",
    "    else:\n",
    "        # Model hyperparameters\n",
    "        params = {'boosting_type': 'dart', \n",
    "                  'colsample_bytree': 0.88, \n",
    "                  'learning_rate': 0.028, \n",
    "                   'min_child_samples': 10, \n",
    "                   'num_leaves': 36, 'reg_alpha': 0.76, \n",
    "                   'reg_lambda': 0.43, \n",
    "                   'subsample_for_bin': 40000, \n",
    "                   'subsample': 0.54, \n",
    "                   'class_weight': 'balanced'}\n",
    "    \n",
    "    # Build the model\n",
    "    model = lgb.LGBMClassifier(**params, objective = 'multiclass', \n",
    "                               n_jobs = -1, n_estimators = 10000,\n",
    "                               random_state = 10)\n",
    "    \n",
    "    # Using stratified kfold cross validation\n",
    "    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True)\n",
    "    \n",
    "    # Hold all the predictions from each fold\n",
    "    predictions = pd.DataFrame()\n",
    "    importances = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Convert to arrays for indexing\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    labels = np.array(labels).reshape((-1 ))\n",
    "    \n",
    "    valid_scores = []\n",
    "    \n",
    "    # Iterate through the folds\n",
    "    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n",
    "        \n",
    "        # Dataframe for fold predictions\n",
    "        fold_predictions = pd.DataFrame()\n",
    "        \n",
    "        # Training and validation data\n",
    "        X_train = features[train_indices]\n",
    "        X_valid = features[valid_indices]\n",
    "        y_train = labels[train_indices]\n",
    "        y_valid = labels[valid_indices]\n",
    "        \n",
    "        # Train with early stopping\n",
    "        model.fit(X_train, y_train, early_stopping_rounds = 100, \n",
    "                  eval_metric = macro_f1_score,\n",
    "                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
    "                  eval_names = ['train', 'valid'],\n",
    "                  verbose = 200)\n",
    "        \n",
    "        # Record the validation fold score\n",
    "        valid_scores.append(model.best_score_['valid']['macro_f1'])\n",
    "        \n",
    "        # Make predictions from the fold as probabilities\n",
    "        fold_probabilitites = model.predict_proba(test_features)\n",
    "        \n",
    "        # Record each prediction for each class as a separate column\n",
    "        for j in range(4):\n",
    "            fold_predictions[(j + 1)] = fold_probabilitites[:, j]\n",
    "            \n",
    "        # Add needed information for predictions \n",
    "        fold_predictions['idhogar'] = test_ids\n",
    "        fold_predictions['fold'] = (i+1)\n",
    "        \n",
    "        # Add the predictions as new rows to the existing predictions\n",
    "        predictions = predictions.append(fold_predictions)\n",
    "        \n",
    "        # Feature importances\n",
    "        importances += model.feature_importances_ / nfolds   \n",
    "        \n",
    "        # Display fold information\n",
    "        display(f'Fold {i + 1}, Validation Score: {round(valid_scores[i], 5)}, Estimators Trained: {model.best_iteration_}')\n",
    "\n",
    "    # Feature importances dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names,\n",
    "                                        'importance': importances})\n",
    "    \n",
    "    valid_scores = np.array(valid_scores)\n",
    "    display(f'{nfolds} cross validation score: {round(valid_scores.mean(), 5)} with std: {round(valid_scores.std(), 5)}.')\n",
    "    \n",
    "    # If we want to examine predictions don't average over folds\n",
    "    if return_preds:\n",
    "        predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n",
    "        predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n",
    "        return predictions, feature_importances\n",
    "    \n",
    "    # Average the predictions over folds\n",
    "    predictions = predictions.groupby('idhogar', as_index = False).mean()\n",
    "    \n",
    "    # Find the class and associated probability\n",
    "    predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n",
    "    predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n",
    "    predictions = predictions.drop(columns = ['fold'])\n",
    "    \n",
    "    # Merge with the base to have one prediction for each individual\n",
    "    submission = submission_base.merge(predictions[['idhogar', 'Target']], on = 'idhogar', how = 'left').drop(columns = ['idhogar'])\n",
    "        \n",
    "    # Fill in the individuals that do not have a head of household with 4 since these will not be scored\n",
    "    submission['Target'] = submission['Target'].fillna(4).astype(np.int8)\n",
    "    \n",
    "    # return the submission and feature importances along with validation scores\n",
    "    return submission, feature_importances, valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = list(final.loc[final['Target'].isnull(), 'idhogar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fold 1, Validation Score: 0.45854, Estimators Trained: 201'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fold 2, Validation Score: 0.39228, Estimators Trained: 121'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fold 3, Validation Score: 0.41043, Estimators Trained: 17'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fold 4, Validation Score: 0.42048, Estimators Trained: 275'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fold 5, Validation Score: 0.45453, Estimators Trained: 335'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'5 cross validation score: 0.42725 with std: 0.02559.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "predictions, gbm_fi = model_gbm(train_set, train_labels, test_set, test_ids, return_preds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>idhogar</th>\n",
       "      <th>fold</th>\n",
       "      <th>Target</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.153845</td>\n",
       "      <td>0.148401</td>\n",
       "      <td>0.153716</td>\n",
       "      <td>0.544038</td>\n",
       "      <td>72958b30c</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.544038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.146805</td>\n",
       "      <td>0.140883</td>\n",
       "      <td>0.512312</td>\n",
       "      <td>5b598fbc9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.512312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.172124</td>\n",
       "      <td>0.175594</td>\n",
       "      <td>0.240187</td>\n",
       "      <td>0.412094</td>\n",
       "      <td>1e2fc704e</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.412094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.167223</td>\n",
       "      <td>0.179329</td>\n",
       "      <td>0.171756</td>\n",
       "      <td>0.481693</td>\n",
       "      <td>8ee7365a8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.481693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.151113</td>\n",
       "      <td>0.173359</td>\n",
       "      <td>0.182136</td>\n",
       "      <td>0.493391</td>\n",
       "      <td>ff69a6fc8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.493391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4    idhogar  fold  Target  confidence\n",
       "0  0.153845  0.148401  0.153716  0.544038  72958b30c     1       4    0.544038\n",
       "1  0.200000  0.146805  0.140883  0.512312  5b598fbc9     1       4    0.512312\n",
       "2  0.172124  0.175594  0.240187  0.412094  1e2fc704e     1       4    0.412094\n",
       "3  0.167223  0.179329  0.171756  0.481693  8ee7365a8     1       4    0.481693\n",
       "4  0.151113  0.173359  0.182136  0.493391  ff69a6fc8     1       4    0.493391"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>meaneduc</td>\n",
       "      <td>1007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>age-std</td>\n",
       "      <td>998.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>escolari/age-sum</td>\n",
       "      <td>919.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>age-sum</td>\n",
       "      <td>874.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>age-max</td>\n",
       "      <td>870.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance\n",
       "69           meaneduc      1007.0\n",
       "204           age-std       998.8\n",
       "211  escolari/age-sum       919.6\n",
       "203           age-sum       874.2\n",
       "202           age-max       870.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_fi.sort_values('importance', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- I really don't understand how this precise implementation is different than a regular one. It seems that it uses soft voting within the function (because you are looping through the kfold and aggregating predictions). This is different than what cross-validation scoring is (indeed, when you run cross-validation scoring on this function, you split the data twice, right?)\n",
    "- can it make a learning curve?\n",
    "- Use some sort of hyperparameter tuning, but it WILL be slow! https://www.kaggle.com/aashita/advanced-pipelines-tutorial\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(features, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(n_estimators=1000, learning_rate=0.02, max_depth=10)\n",
    "xgb.fit(train_X, train_y, early_stopping_rounds=100, \n",
    "             eval_set=[(test_X, test_y)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation F1 Score = 0.3816 with std = 0.0187\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_params = {\"eval_set\": [(test_X, test_y)], \n",
    "              \"early_stopping_rounds\": 100, \n",
    "              \"verbose\": False} \n",
    "cv_score = cross_val_score(xgb, train_X, train_y, cv=kfold, scoring=f1_scorer, n_jobs=-1, fit_params=fit_params)\n",
    "print(f'Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'dart', \n",
    "                  'colsample_bytree': 0.88, \n",
    "                  'learning_rate': 0.028, \n",
    "                   'min_child_samples': 10, \n",
    "                   'num_leaves': 36, 'reg_alpha': 0.76, \n",
    "                   'reg_lambda': 0.43, \n",
    "                   'subsample_for_bin': 40000, \n",
    "                   'subsample': 0.54, \n",
    "                   'class_weight': 'balanced'}\n",
    "\n",
    "model = lgb.LGBMClassifier(**params, objective = 'multiclass', \n",
    "                               n_jobs = -1, n_estimators = 10000,\n",
    "                               random_state = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation F1 Score = 0.4113 with std = 0.0175\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_params = {\"eval_set\": [(test_X, test_y)], \n",
    "              \"early_stopping_rounds\": 100, \n",
    "              \"verbose\": False} \n",
    "cv_score = cross_val_score(model, train_X, train_y, cv=kfold, scoring=f1_scorer, n_jobs=-1, fit_params=fit_params)\n",
    "print(f'Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation F1 Score = 0.4093 with std = 0.0156\n",
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_params = {\"eval_set\": [(test_X, test_y)], \n",
    "              \"early_stopping_rounds\": 50, \n",
    "              \"verbose\": False} \n",
    "cv_score = cross_val_score(model, train_X, train_y, cv=kfold, scoring=f1_scorer, n_jobs=-1, fit_params=fit_params)\n",
    "print(f'Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', class_weight='balanced',\n",
       "        colsample_bytree=0.88, learning_rate=0.028, max_depth=-1,\n",
       "        min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=10000, n_jobs=-1, num_leaves=36,\n",
       "        objective='multiclass', random_state=10, reg_alpha=0.76,\n",
       "        reg_lambda=0.43, silent=True, subsample=0.54,\n",
       "        subsample_for_bin=40000, subsample_freq=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, early_stopping_rounds=100, \n",
    "             eval_set=[(test_X, test_y)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({'feature': feature_names,\n",
    "                                    'importance': model.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>age-std</td>\n",
       "      <td>6042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>age-max</td>\n",
       "      <td>5424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>escolari/age-sum</td>\n",
       "      <td>4836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>age-min</td>\n",
       "      <td>4721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>age-sum</td>\n",
       "      <td>4600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance\n",
       "204           age-std        6042\n",
       "202           age-max        5424\n",
       "211  escolari/age-sum        4836\n",
       "201           age-min        4721\n",
       "203           age-sum        4600"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.sort_values('importance', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: \n",
    "Really can't figure out https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough. Below I try using his best parameters, but they do very poorly. Guessing by his high learning rate and low n_estimators, I wonder if this is best because his algorithm splits data into 5 folds with soft voting, whereas the regular implementation would have just one training set. \n",
    "It seems that https://github.com/hyperopt/hyperopt-sklearn/blob/master/notebooks/Demo-Iris.ipynb has some but not all sklearn algorithms included. \n",
    "\n",
    "\n",
    "### TODO: try https://www.kaggle.com/yassinealouini/hyperopt-the-xgboost-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyp = {'boosting_type': 'dart',\n",
    " 'colsample_bytree': 0.6096416248120604,\n",
    " 'learning_rate': 0.19779582059725404,\n",
    " 'limit_max_depth': True,\n",
    " 'max_depth': 24,\n",
    " 'min_child_samples': 35,\n",
    " 'num_leaves': 42,\n",
    " 'reg_alpha': 0.41161294322049163,\n",
    " 'reg_lambda': 0.6745579773545685,\n",
    " 'subsample_for_bin': 50000,\n",
    " 'drop_rate': 0.48718668776524016,\n",
    " 'subsample': 0.5220648456225067,\n",
    " 'subsample_freq': 9,\n",
    " 'n_estimators': 120}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(**best_hyp, objective = 'multiclass', \n",
    "                               n_jobs = -1,\n",
    "                               random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation F1 Score = 0.4084 with std = 0.01\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_params = {\"eval_set\": [(test_X, test_y)], \n",
    "              \"early_stopping_rounds\": 100, \n",
    "              \"verbose\": False} \n",
    "cv_score = cross_val_score(model, train_X, train_y, cv=kfold, scoring=f1_scorer, n_jobs=-1, fit_params=fit_params)\n",
    "print(f'Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well, let's at least do a very quick check of different max_depts\n",
    "Note: of [12,16,20,25,30,35,40], max_depth=20 performed the best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = dict(max_depth=[12,16,20])\n",
    "\n",
    "params = {'boosting_type': 'dart', \n",
    "                  'colsample_bytree': 0.88, \n",
    "                  'learning_rate': 0.028, \n",
    "                   'min_child_samples': 10, \n",
    "                   #'num_leaves': 36, \n",
    "                   'reg_alpha': 0.76, \n",
    "                   'reg_lambda': 0.43, \n",
    "                   'subsample_for_bin': 40000, \n",
    "                   'subsample': 0.54, \n",
    "                   'class_weight': 'balanced'}\n",
    "\n",
    "fit_params = {\"eval_set\": [(test_X, test_y)], \n",
    "              \"early_stopping_rounds\": 100, \n",
    "              \"verbose\": False} \n",
    "\n",
    "model = lgb.LGBMClassifier(**params, objective = 'multiclass', \n",
    "                               n_jobs = -1, n_estimators = 10000,\n",
    "                               random_state = 10)\n",
    "\n",
    "grid = GridSearchCV(model, param_grid=param_grid, fit_params=fit_params, cv=kfold, scoring=f1_scorer, n_jobs=-1)\n",
    "grid.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...ggle\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000179129BCC00, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'c:\\users\\zrankin\\appdata\\local\\continuum\\minicon...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'c:\\users\\zrankin\\appdata\\local\\continuum\\minicon...vs\\kaggle\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...ggle\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'c:\\\\users\\\\z...le\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...ggle\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000179129BCC00, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'c:\\users\\zrankin\\appdata\\local\\continuum\\minicon...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'c:\\users\\zrankin\\appdata\\local\\continuum\\minicon...vs\\kaggle\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...ggle\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'c:\\\\users\\\\z...le\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1429                         logger.warning('Executing %s took %.3f seconds',\n   1430                                        _format_handle(handle), dt)\n   1431                 finally:\n   1432                     self._current_handle = None\n   1433             else:\n-> 1434                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(836, 1)>>\n   1435         handle = None  # Needed to break cycles when an exception occurs.\n   1436 \n   1437     def _set_coroutine_wrapper(self, enabled):\n   1438         try:\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(836, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (836, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=836, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 1, 13, 14, 27, 573857, tzinfo=tzutc()), 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'session': 'eb2930d46f4343ae830dd7998ec63da8', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'eb2930d46f4343ae830dd7998ec63da8']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 1, 13, 14, 27, 573857, tzinfo=tzutc()), 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'session': 'eb2930d46f4343ae830dd7998ec63da8', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'eb2930d46f4343ae830dd7998ec63da8'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 1, 13, 14, 27, 573857, tzinfo=tzutc()), 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'session': 'eb2930d46f4343ae830dd7998ec63da8', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-118-ccf4e0ac5cf0>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 17938c7fe10, executio...rue silent=False shell_futures=True> result=None>)\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n   2906                 code = compiler(mod, cell_name, \"single\")\n-> 2907                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000017938A8BC90, file \"<ipython-input-118-ccf4e0ac5cf0>\", line 1>\n        result = <ExecutionResult object at 17938c7fe10, executio...rue silent=False shell_futures=True> result=None>\n   2908                     return True\n   2909 \n   2910             # Flush softspace\n   2911             if softspace(sys.stdout, 0):\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000017938A8BC90, file \"<ipython-input-118-ccf4e0ac5cf0>\", line 1>, result=<ExecutionResult object at 17938c7fe10, executio...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000017938A8BC90, file \"<ipython-input-118-ccf4e0ac5cf0>\", line 1>\n        self.user_global_ns = {'Counter': <class 'collections.Counter'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HyperoptEstimator': <class 'hpsklearn.estimator.hyperopt_estimator'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', \"import os\\nimport sys\\nimport numpy as np\\nimport p..._ipython().run_line_magic('matplotlib', 'inline')\", '# # Tools for developing code\\n# %load_ext autore...t in sys.path:\\n#     sys.path.append(module_path)', \"train = pd.read_csv('../input/train.csv')\\ntest = pd.read_csv('../input/test.csv')\", 'mapping = {\"yes\": 1, \"no\": 0}\\n\\n# Apply same oper...in[[\\'dependency\\', \\'edjefa\\', \\'edjefe\\']].describe()', \"# Add null Target column to test\\ntest['Target'] ...an\\ndata = train.append(test, ignore_index = True)\", \"# Groupby the household and figure out the numbe...ll have the same target.'.format(len(not_equal)))\", \"# Iterate through each household\\nfor household i...ll have the same target.'.format(len(not_equal)))\", \"# Number of missing in each column\\nmissing = pd....cent', ascending = False).head(10).drop('Target')\", \"# Missing num tablets means you don't have one\\nd...l()\\n\\ndata.loc[data['rez_esc'] > 5, 'rez_esc'] = 5\", \"id_ = ['Id', 'idhogar', 'Target']\\n\\nind_bool = ['...vered every variable: ', len(x) == data.shape[1])\", '# Remove squared variables\\ndata = data.drop(colu...id_ + hh_bool + hh_cont + hh_ordered]\\nheads.shape', '# Create correlation matrix\\ncorr_matrix = heads....lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', \"heads = heads.drop(columns = ['tamhog', 'hogar_t...hhsize-diff'] = heads['tamviv'] - heads['hhsize']\", \"elec = []\\n\\n# Assign values\\nfor i, row in heads.i...ec\\nheads['elec-missing'] = heads['elec'].isnull()\", \"heads = heads.drop(columns = 'area2')\", \"# Wall ordinal variable\\nheads['walls'] = np.argm...nt-per-capita'] = heads['v2a1'] / heads['tamviv']\", 'household_feats = list(heads.columns)', 'ind = data[id_ + ind_bool + ind_ordered]\\nind.shape', '# Create correlation matrix\\ncorr_matrix = ind.co...lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4:         dependency       edjefa       edjefe\ncou...0000\nmax       8.000000    21.000000    21.000000, 8:               total   percent\nrez_esc       2758...11      0  0.000000\nparentesco12      0  0.000000, 11: (10307, 99), 12: ['coopele', 'area2', 'tamhog', 'hhsize', 'hogar_total'], 18: (33413, 40), 19: ['female'], 22: (33413, 40), 23: count    33413.000000\nmean         1.214886\nstd ...\nmax          2.000000\nName: tech, dtype: float64, 24:           v18q                           dis    ...1   4     4  0.0      0  \n\n[5 rows x 234 columns], 25:            v18q-min  v18q-max  v18q-sum  v18q-co...       0.0            0  \n\n[5 rows x 234 columns], ...}, 'PermutationImportance': <class 'eli5.sklearn.permutation_importance.PermutationImportance'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFECV': <class 'sklearn.feature_selection.rfe.RFECV'>, ...}\n        self.user_ns = {'Counter': <class 'collections.Counter'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HyperoptEstimator': <class 'hpsklearn.estimator.hyperopt_estimator'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', \"import os\\nimport sys\\nimport numpy as np\\nimport p..._ipython().run_line_magic('matplotlib', 'inline')\", '# # Tools for developing code\\n# %load_ext autore...t in sys.path:\\n#     sys.path.append(module_path)', \"train = pd.read_csv('../input/train.csv')\\ntest = pd.read_csv('../input/test.csv')\", 'mapping = {\"yes\": 1, \"no\": 0}\\n\\n# Apply same oper...in[[\\'dependency\\', \\'edjefa\\', \\'edjefe\\']].describe()', \"# Add null Target column to test\\ntest['Target'] ...an\\ndata = train.append(test, ignore_index = True)\", \"# Groupby the household and figure out the numbe...ll have the same target.'.format(len(not_equal)))\", \"# Iterate through each household\\nfor household i...ll have the same target.'.format(len(not_equal)))\", \"# Number of missing in each column\\nmissing = pd....cent', ascending = False).head(10).drop('Target')\", \"# Missing num tablets means you don't have one\\nd...l()\\n\\ndata.loc[data['rez_esc'] > 5, 'rez_esc'] = 5\", \"id_ = ['Id', 'idhogar', 'Target']\\n\\nind_bool = ['...vered every variable: ', len(x) == data.shape[1])\", '# Remove squared variables\\ndata = data.drop(colu...id_ + hh_bool + hh_cont + hh_ordered]\\nheads.shape', '# Create correlation matrix\\ncorr_matrix = heads....lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', \"heads = heads.drop(columns = ['tamhog', 'hogar_t...hhsize-diff'] = heads['tamviv'] - heads['hhsize']\", \"elec = []\\n\\n# Assign values\\nfor i, row in heads.i...ec\\nheads['elec-missing'] = heads['elec'].isnull()\", \"heads = heads.drop(columns = 'area2')\", \"# Wall ordinal variable\\nheads['walls'] = np.argm...nt-per-capita'] = heads['v2a1'] / heads['tamviv']\", 'household_feats = list(heads.columns)', 'ind = data[id_ + ind_bool + ind_ordered]\\nind.shape', '# Create correlation matrix\\ncorr_matrix = ind.co...lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4:         dependency       edjefa       edjefe\ncou...0000\nmax       8.000000    21.000000    21.000000, 8:               total   percent\nrez_esc       2758...11      0  0.000000\nparentesco12      0  0.000000, 11: (10307, 99), 12: ['coopele', 'area2', 'tamhog', 'hhsize', 'hogar_total'], 18: (33413, 40), 19: ['female'], 22: (33413, 40), 23: count    33413.000000\nmean         1.214886\nstd ...\nmax          2.000000\nName: tech, dtype: float64, 24:           v18q                           dis    ...1   4     4  0.0      0  \n\n[5 rows x 234 columns], 25:            v18q-min  v18q-max  v18q-sum  v18q-co...       0.0            0  \n\n[5 rows x 234 columns], ...}, 'PermutationImportance': <class 'eli5.sklearn.permutation_importance.PermutationImportance'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFECV': <class 'sklearn.feature_selection.rfe.RFECV'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\zrankin\\Documents\\github\\poverty_prediction\\notebooks\\<ipython-input-118-ccf4e0ac5cf0> in <module>()\n----> 1 get_ipython().run_cell_magic('time', '', \"param_grid = dict(num_leaves=[32,36,40])\\nparams = {'boosting_type': 'dart', \\n                  'colsample_bytree': 0.88, \\n                  'learning_rate': 0.028, \\n                   'min_child_samples': 10, \\n                   'num_leaves': 36, \\n                   'reg_alpha': 0.76, \\n                   'reg_lambda': 0.43, \\n                   'subsample_for_bin': 40000, \\n                   'subsample': 0.54, \\n                   'class_weight': 'balanced'}\\n\\n\\ngrid = GridSearchCV(model, param_grid=param_grid, fit_params=fit_params, cv=kfold, scoring=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\")\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell='param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)')\n   2162             # This will need to be updated if the internal calling logic gets\n   2163             # refactored, or else we'll be expanding the wrong variables.\n   2164             stack_depth = 2\n   2165             magic_arg_s = self.var_expand(line, stack_depth)\n   2166             with self.builtin_trap:\n-> 2167                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = 'param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)'\n   2168             return result\n   2169 \n   2170     def find_line_magic(self, magic_name):\n   2171         \"\"\"Find and return a line magic by name.\n\n...........................................................................\nC:\\Users\\zrankin\\Documents\\github\\poverty_prediction\\notebooks\\<decorator-gen-63> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)', local_ns=None)\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', 'param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)', None), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', 'param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)', None)\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\magics\\execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)', local_ns=None)\n   1232                 return\n   1233             end = clock2()\n   1234         else:\n   1235             st = clock2()\n   1236             try:\n-> 1237                 exec(code, glob, local_ns)\n        code = <code object <module> at 0x0000017936AC2B70, file \"<timed exec>\", line 1>\n        glob = {'Counter': <class 'collections.Counter'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HyperoptEstimator': <class 'hpsklearn.estimator.hyperopt_estimator'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', \"import os\\nimport sys\\nimport numpy as np\\nimport p..._ipython().run_line_magic('matplotlib', 'inline')\", '# # Tools for developing code\\n# %load_ext autore...t in sys.path:\\n#     sys.path.append(module_path)', \"train = pd.read_csv('../input/train.csv')\\ntest = pd.read_csv('../input/test.csv')\", 'mapping = {\"yes\": 1, \"no\": 0}\\n\\n# Apply same oper...in[[\\'dependency\\', \\'edjefa\\', \\'edjefe\\']].describe()', \"# Add null Target column to test\\ntest['Target'] ...an\\ndata = train.append(test, ignore_index = True)\", \"# Groupby the household and figure out the numbe...ll have the same target.'.format(len(not_equal)))\", \"# Iterate through each household\\nfor household i...ll have the same target.'.format(len(not_equal)))\", \"# Number of missing in each column\\nmissing = pd....cent', ascending = False).head(10).drop('Target')\", \"# Missing num tablets means you don't have one\\nd...l()\\n\\ndata.loc[data['rez_esc'] > 5, 'rez_esc'] = 5\", \"id_ = ['Id', 'idhogar', 'Target']\\n\\nind_bool = ['...vered every variable: ', len(x) == data.shape[1])\", '# Remove squared variables\\ndata = data.drop(colu...id_ + hh_bool + hh_cont + hh_ordered]\\nheads.shape', '# Create correlation matrix\\ncorr_matrix = heads....lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', \"heads = heads.drop(columns = ['tamhog', 'hogar_t...hhsize-diff'] = heads['tamviv'] - heads['hhsize']\", \"elec = []\\n\\n# Assign values\\nfor i, row in heads.i...ec\\nheads['elec-missing'] = heads['elec'].isnull()\", \"heads = heads.drop(columns = 'area2')\", \"# Wall ordinal variable\\nheads['walls'] = np.argm...nt-per-capita'] = heads['v2a1'] / heads['tamviv']\", 'household_feats = list(heads.columns)', 'ind = data[id_ + ind_bool + ind_ordered]\\nind.shape', '# Create correlation matrix\\ncorr_matrix = ind.co...lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4:         dependency       edjefa       edjefe\ncou...0000\nmax       8.000000    21.000000    21.000000, 8:               total   percent\nrez_esc       2758...11      0  0.000000\nparentesco12      0  0.000000, 11: (10307, 99), 12: ['coopele', 'area2', 'tamhog', 'hhsize', 'hogar_total'], 18: (33413, 40), 19: ['female'], 22: (33413, 40), 23: count    33413.000000\nmean         1.214886\nstd ...\nmax          2.000000\nName: tech, dtype: float64, 24:           v18q                           dis    ...1   4     4  0.0      0  \n\n[5 rows x 234 columns], 25:            v18q-min  v18q-max  v18q-sum  v18q-co...       0.0            0  \n\n[5 rows x 234 columns], ...}, 'PermutationImportance': <class 'eli5.sklearn.permutation_importance.PermutationImportance'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFECV': <class 'sklearn.feature_selection.rfe.RFECV'>, ...}\n        local_ns = None\n   1238             except:\n   1239                 self.shell.showtraceback()\n   1240                 return\n   1241             end = clock2()\n\n...........................................................................\nC:\\Users\\zrankin\\Documents\\github\\poverty_prediction\\notebooks\\<timed exec> in <module>()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=StratifiedKFold(n_splits=5, rand...=make_scorer(f1_score, average=macro), verbose=0), X=array([[0., 0., 1., ..., 0., 0., 0.],\n       [0...., 0., 1.],\n       [0., 0., 1., ..., 0., 0., 0.]]), y=array([4, 3, 3, ..., 4, 4, 4]), groups=None, **fit_params={'early_stopping_rounds': 100, 'eval_set': [(array([[0., 0., 1., ..., 0., 0., 0.],\n       [0...., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of StratifiedKFold(n_splits=5, random_state=1, shuffle=False)>\n        X = array([[0., 0., 1., ..., 0., 0., 0.],\n       [0...., 0., 1.],\n       [0., 0., 1., ..., 0., 0., 0.]])\n        y = array([4, 3, 3, ..., 4, 4, 4])\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Oct  1 08:14:29 2018\nPID: 12832Python 3.6.6: c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\python.exe\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([4, 3, 3, ..., 4, 4, 4]), {'score': make_scorer(f1_score, average=macro)}, array([ 374,  378,  382, ..., 2226, 2227, 2228]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), 0, {'num_leaves': 32}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([4, 3, 3, ..., 4, 4, 4]), {'score': make_scorer(f1_score, average=macro)}, array([ 374,  378,  382, ..., 2226, 2227, 2228]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), 0, {'num_leaves': 32})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), X=memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), y=array([4, 3, 3, ..., 4, 4, 4]), scorer={'score': make_scorer(f1_score, average=macro)}, train=array([ 374,  378,  382, ..., 2226, 2227, 2228]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), verbose=0, parameters={'num_leaves': 32}, fit_params={'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method LGBMClassifier.fit of LGBMClassifi...      subsample_for_bin=40000, subsample_freq=0)>\n        X_train = memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]])\n        y_train = array([1, 1, 1, ..., 4, 4, 4])\n        fit_params = {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\sklearn.py in fit(self=LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), X=memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), y=array([1, 1, 1, ..., 4, 4, 4]), sample_weight=None, init_score=None, eval_set=[(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], eval_names=None, eval_sample_weight=None, eval_class_weight=None, eval_init_score=None, eval_metric='multi_logloss', early_stopping_rounds=100, verbose=False, feature_name='auto', categorical_feature='auto', callbacks=None)\n    678                 eval_set = [eval_set]\n    679             for i, (valid_x, valid_y) in enumerate(eval_set):\n    680                 if valid_x is X and valid_y is y:\n    681                     eval_set[i] = (valid_x, _y)\n    682                 else:\n--> 683                     eval_set[i] = (valid_x, self._le.transform(valid_y))\n        eval_set = [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))]\n        i = 0\n        valid_x = memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]])\n        self._le.transform = <bound method LabelEncoder.transform of LabelEncoder()>\n        valid_y = array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64)\n    684 \n    685         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n    686                                         init_score=init_score, eval_set=eval_set,\n    687                                         eval_names=eval_names,\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py in transform(self=LabelEncoder(), y=array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))\n    128         y = column_or_1d(y, warn=True)\n    129 \n    130         classes = np.unique(y)\n    131         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n    132             diff = np.setdiff1d(classes, self.classes_)\n--> 133             raise ValueError(\"y contains new labels: %s\" % str(diff))\n        diff = array([0], dtype=int64)\n    134         return np.searchsorted(self.classes_, y)\n    135 \n    136     def inverse_transform(self, y):\n    137         \"\"\"Transform labels back to original encoding.\n\nValueError: y contains new labels: [0]\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\sklearn.py\", line 683, in fit\n    eval_set[i] = (valid_x, self._le.transform(valid_y))\n  File \"c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py\", line 133, in transform\n    raise ValueError(\"y contains new labels: %s\" % str(diff))\nValueError: y contains new labels: [0]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Oct  1 08:14:29 2018\nPID: 12832Python 3.6.6: c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\python.exe\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([4, 3, 3, ..., 4, 4, 4]), {'score': make_scorer(f1_score, average=macro)}, array([ 374,  378,  382, ..., 2226, 2227, 2228]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), 0, {'num_leaves': 32}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([4, 3, 3, ..., 4, 4, 4]), {'score': make_scorer(f1_score, average=macro)}, array([ 374,  378,  382, ..., 2226, 2227, 2228]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), 0, {'num_leaves': 32})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), X=memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), y=array([4, 3, 3, ..., 4, 4, 4]), scorer={'score': make_scorer(f1_score, average=macro)}, train=array([ 374,  378,  382, ..., 2226, 2227, 2228]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), verbose=0, parameters={'num_leaves': 32}, fit_params={'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method LGBMClassifier.fit of LGBMClassifi...      subsample_for_bin=40000, subsample_freq=0)>\n        X_train = memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]])\n        y_train = array([1, 1, 1, ..., 4, 4, 4])\n        fit_params = {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\sklearn.py in fit(self=LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), X=memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), y=array([1, 1, 1, ..., 4, 4, 4]), sample_weight=None, init_score=None, eval_set=[(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], eval_names=None, eval_sample_weight=None, eval_class_weight=None, eval_init_score=None, eval_metric='multi_logloss', early_stopping_rounds=100, verbose=False, feature_name='auto', categorical_feature='auto', callbacks=None)\n    678                 eval_set = [eval_set]\n    679             for i, (valid_x, valid_y) in enumerate(eval_set):\n    680                 if valid_x is X and valid_y is y:\n    681                     eval_set[i] = (valid_x, _y)\n    682                 else:\n--> 683                     eval_set[i] = (valid_x, self._le.transform(valid_y))\n        eval_set = [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))]\n        i = 0\n        valid_x = memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]])\n        self._le.transform = <bound method LabelEncoder.transform of LabelEncoder()>\n        valid_y = array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64)\n    684 \n    685         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n    686                                         init_score=init_score, eval_set=eval_set,\n    687                                         eval_names=eval_names,\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py in transform(self=LabelEncoder(), y=array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))\n    128         y = column_or_1d(y, warn=True)\n    129 \n    130         classes = np.unique(y)\n    131         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n    132             diff = np.setdiff1d(classes, self.classes_)\n--> 133             raise ValueError(\"y contains new labels: %s\" % str(diff))\n        diff = array([0], dtype=int64)\n    134         return np.searchsorted(self.classes_, y)\n    135 \n    136     def inverse_transform(self, y):\n    137         \"\"\"Transform labels back to original encoding.\n\nValueError: y contains new labels: [0]\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Oct  1 08:14:29 2018\nPID: 12832Python 3.6.6: c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\python.exe\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([4, 3, 3, ..., 4, 4, 4]), {'score': make_scorer(f1_score, average=macro)}, array([ 374,  378,  382, ..., 2226, 2227, 2228]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), 0, {'num_leaves': 32}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([4, 3, 3, ..., 4, 4, 4]), {'score': make_scorer(f1_score, average=macro)}, array([ 374,  378,  382, ..., 2226, 2227, 2228]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), 0, {'num_leaves': 32})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), X=memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), y=array([4, 3, 3, ..., 4, 4, 4]), scorer={'score': make_scorer(f1_score, average=macro)}, train=array([ 374,  378,  382, ..., 2226, 2227, 2228]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), verbose=0, parameters={'num_leaves': 32}, fit_params={'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method LGBMClassifier.fit of LGBMClassifi...      subsample_for_bin=40000, subsample_freq=0)>\n        X_train = memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]])\n        y_train = array([1, 1, 1, ..., 4, 4, 4])\n        fit_params = {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\sklearn.py in fit(self=LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), X=memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), y=array([1, 1, 1, ..., 4, 4, 4]), sample_weight=None, init_score=None, eval_set=[(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], eval_names=None, eval_sample_weight=None, eval_class_weight=None, eval_init_score=None, eval_metric='multi_logloss', early_stopping_rounds=100, verbose=False, feature_name='auto', categorical_feature='auto', callbacks=None)\n    678                 eval_set = [eval_set]\n    679             for i, (valid_x, valid_y) in enumerate(eval_set):\n    680                 if valid_x is X and valid_y is y:\n    681                     eval_set[i] = (valid_x, _y)\n    682                 else:\n--> 683                     eval_set[i] = (valid_x, self._le.transform(valid_y))\n        eval_set = [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))]\n        i = 0\n        valid_x = memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]])\n        self._le.transform = <bound method LabelEncoder.transform of LabelEncoder()>\n        valid_y = array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64)\n    684 \n    685         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n    686                                         init_score=init_score, eval_set=eval_set,\n    687                                         eval_names=eval_names,\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py in transform(self=LabelEncoder(), y=array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))\n    128         y = column_or_1d(y, warn=True)\n    129 \n    130         classes = np.unique(y)\n    131         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n    132             diff = np.setdiff1d(classes, self.classes_)\n--> 133             raise ValueError(\"y contains new labels: %s\" % str(diff))\n        diff = array([0], dtype=int64)\n    134         return np.searchsorted(self.classes_, y)\n    135 \n    136     def inverse_transform(self, y):\n    137         \"\"\"Transform labels back to original encoding.\n\nValueError: y contains new labels: [0]\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 640\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...ggle\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000179129BCC00, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'c:\\users\\zrankin\\appdata\\local\\continuum\\minicon...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'c:\\users\\zrankin\\appdata\\local\\continuum\\minicon...vs\\kaggle\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...ggle\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'c:\\\\users\\\\z...le\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...ggle\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000179129BCC00, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'c:\\users\\zrankin\\appdata\\local\\continuum\\minicon...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'c:\\users\\zrankin\\appdata\\local\\continuum\\minicon...vs\\kaggle\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...ggle\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'c:\\\\users\\\\z...le\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1429                         logger.warning('Executing %s took %.3f seconds',\n   1430                                        _format_handle(handle), dt)\n   1431                 finally:\n   1432                     self._current_handle = None\n   1433             else:\n-> 1434                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(836, 1)>>\n   1435         handle = None  # Needed to break cycles when an exception occurs.\n   1436 \n   1437     def _set_coroutine_wrapper(self, enabled):\n   1438         try:\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(836, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (836, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=836, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 1, 13, 14, 27, 573857, tzinfo=tzutc()), 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'session': 'eb2930d46f4343ae830dd7998ec63da8', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'eb2930d46f4343ae830dd7998ec63da8']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 1, 13, 14, 27, 573857, tzinfo=tzutc()), 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'session': 'eb2930d46f4343ae830dd7998ec63da8', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'eb2930d46f4343ae830dd7998ec63da8'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 1, 13, 14, 27, 573857, tzinfo=tzutc()), 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'session': 'eb2930d46f4343ae830dd7998ec63da8', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd9fd04005580454482dd4ca154eb03a0', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='%%time\\nparam_grid = dict(num_leaves=[32,36,40])\\n...f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\\n', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-118-ccf4e0ac5cf0>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 17938c7fe10, executio...rue silent=False shell_futures=True> result=None>)\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n   2906                 code = compiler(mod, cell_name, \"single\")\n-> 2907                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000017938A8BC90, file \"<ipython-input-118-ccf4e0ac5cf0>\", line 1>\n        result = <ExecutionResult object at 17938c7fe10, executio...rue silent=False shell_futures=True> result=None>\n   2908                     return True\n   2909 \n   2910             # Flush softspace\n   2911             if softspace(sys.stdout, 0):\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000017938A8BC90, file \"<ipython-input-118-ccf4e0ac5cf0>\", line 1>, result=<ExecutionResult object at 17938c7fe10, executio...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000017938A8BC90, file \"<ipython-input-118-ccf4e0ac5cf0>\", line 1>\n        self.user_global_ns = {'Counter': <class 'collections.Counter'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HyperoptEstimator': <class 'hpsklearn.estimator.hyperopt_estimator'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', \"import os\\nimport sys\\nimport numpy as np\\nimport p..._ipython().run_line_magic('matplotlib', 'inline')\", '# # Tools for developing code\\n# %load_ext autore...t in sys.path:\\n#     sys.path.append(module_path)', \"train = pd.read_csv('../input/train.csv')\\ntest = pd.read_csv('../input/test.csv')\", 'mapping = {\"yes\": 1, \"no\": 0}\\n\\n# Apply same oper...in[[\\'dependency\\', \\'edjefa\\', \\'edjefe\\']].describe()', \"# Add null Target column to test\\ntest['Target'] ...an\\ndata = train.append(test, ignore_index = True)\", \"# Groupby the household and figure out the numbe...ll have the same target.'.format(len(not_equal)))\", \"# Iterate through each household\\nfor household i...ll have the same target.'.format(len(not_equal)))\", \"# Number of missing in each column\\nmissing = pd....cent', ascending = False).head(10).drop('Target')\", \"# Missing num tablets means you don't have one\\nd...l()\\n\\ndata.loc[data['rez_esc'] > 5, 'rez_esc'] = 5\", \"id_ = ['Id', 'idhogar', 'Target']\\n\\nind_bool = ['...vered every variable: ', len(x) == data.shape[1])\", '# Remove squared variables\\ndata = data.drop(colu...id_ + hh_bool + hh_cont + hh_ordered]\\nheads.shape', '# Create correlation matrix\\ncorr_matrix = heads....lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', \"heads = heads.drop(columns = ['tamhog', 'hogar_t...hhsize-diff'] = heads['tamviv'] - heads['hhsize']\", \"elec = []\\n\\n# Assign values\\nfor i, row in heads.i...ec\\nheads['elec-missing'] = heads['elec'].isnull()\", \"heads = heads.drop(columns = 'area2')\", \"# Wall ordinal variable\\nheads['walls'] = np.argm...nt-per-capita'] = heads['v2a1'] / heads['tamviv']\", 'household_feats = list(heads.columns)', 'ind = data[id_ + ind_bool + ind_ordered]\\nind.shape', '# Create correlation matrix\\ncorr_matrix = ind.co...lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4:         dependency       edjefa       edjefe\ncou...0000\nmax       8.000000    21.000000    21.000000, 8:               total   percent\nrez_esc       2758...11      0  0.000000\nparentesco12      0  0.000000, 11: (10307, 99), 12: ['coopele', 'area2', 'tamhog', 'hhsize', 'hogar_total'], 18: (33413, 40), 19: ['female'], 22: (33413, 40), 23: count    33413.000000\nmean         1.214886\nstd ...\nmax          2.000000\nName: tech, dtype: float64, 24:           v18q                           dis    ...1   4     4  0.0      0  \n\n[5 rows x 234 columns], 25:            v18q-min  v18q-max  v18q-sum  v18q-co...       0.0            0  \n\n[5 rows x 234 columns], ...}, 'PermutationImportance': <class 'eli5.sklearn.permutation_importance.PermutationImportance'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFECV': <class 'sklearn.feature_selection.rfe.RFECV'>, ...}\n        self.user_ns = {'Counter': <class 'collections.Counter'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HyperoptEstimator': <class 'hpsklearn.estimator.hyperopt_estimator'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', \"import os\\nimport sys\\nimport numpy as np\\nimport p..._ipython().run_line_magic('matplotlib', 'inline')\", '# # Tools for developing code\\n# %load_ext autore...t in sys.path:\\n#     sys.path.append(module_path)', \"train = pd.read_csv('../input/train.csv')\\ntest = pd.read_csv('../input/test.csv')\", 'mapping = {\"yes\": 1, \"no\": 0}\\n\\n# Apply same oper...in[[\\'dependency\\', \\'edjefa\\', \\'edjefe\\']].describe()', \"# Add null Target column to test\\ntest['Target'] ...an\\ndata = train.append(test, ignore_index = True)\", \"# Groupby the household and figure out the numbe...ll have the same target.'.format(len(not_equal)))\", \"# Iterate through each household\\nfor household i...ll have the same target.'.format(len(not_equal)))\", \"# Number of missing in each column\\nmissing = pd....cent', ascending = False).head(10).drop('Target')\", \"# Missing num tablets means you don't have one\\nd...l()\\n\\ndata.loc[data['rez_esc'] > 5, 'rez_esc'] = 5\", \"id_ = ['Id', 'idhogar', 'Target']\\n\\nind_bool = ['...vered every variable: ', len(x) == data.shape[1])\", '# Remove squared variables\\ndata = data.drop(colu...id_ + hh_bool + hh_cont + hh_ordered]\\nheads.shape', '# Create correlation matrix\\ncorr_matrix = heads....lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', \"heads = heads.drop(columns = ['tamhog', 'hogar_t...hhsize-diff'] = heads['tamviv'] - heads['hhsize']\", \"elec = []\\n\\n# Assign values\\nfor i, row in heads.i...ec\\nheads['elec-missing'] = heads['elec'].isnull()\", \"heads = heads.drop(columns = 'area2')\", \"# Wall ordinal variable\\nheads['walls'] = np.argm...nt-per-capita'] = heads['v2a1'] / heads['tamviv']\", 'household_feats = list(heads.columns)', 'ind = data[id_ + ind_bool + ind_ordered]\\nind.shape', '# Create correlation matrix\\ncorr_matrix = ind.co...lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4:         dependency       edjefa       edjefe\ncou...0000\nmax       8.000000    21.000000    21.000000, 8:               total   percent\nrez_esc       2758...11      0  0.000000\nparentesco12      0  0.000000, 11: (10307, 99), 12: ['coopele', 'area2', 'tamhog', 'hhsize', 'hogar_total'], 18: (33413, 40), 19: ['female'], 22: (33413, 40), 23: count    33413.000000\nmean         1.214886\nstd ...\nmax          2.000000\nName: tech, dtype: float64, 24:           v18q                           dis    ...1   4     4  0.0      0  \n\n[5 rows x 234 columns], 25:            v18q-min  v18q-max  v18q-sum  v18q-co...       0.0            0  \n\n[5 rows x 234 columns], ...}, 'PermutationImportance': <class 'eli5.sklearn.permutation_importance.PermutationImportance'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFECV': <class 'sklearn.feature_selection.rfe.RFECV'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\zrankin\\Documents\\github\\poverty_prediction\\notebooks\\<ipython-input-118-ccf4e0ac5cf0> in <module>()\n----> 1 get_ipython().run_cell_magic('time', '', \"param_grid = dict(num_leaves=[32,36,40])\\nparams = {'boosting_type': 'dart', \\n                  'colsample_bytree': 0.88, \\n                  'learning_rate': 0.028, \\n                   'min_child_samples': 10, \\n                   'num_leaves': 36, \\n                   'reg_alpha': 0.76, \\n                   'reg_lambda': 0.43, \\n                   'subsample_for_bin': 40000, \\n                   'subsample': 0.54, \\n                   'class_weight': 'balanced'}\\n\\n\\ngrid = GridSearchCV(model, param_grid=param_grid, fit_params=fit_params, cv=kfold, scoring=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)\")\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell='param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)')\n   2162             # This will need to be updated if the internal calling logic gets\n   2163             # refactored, or else we'll be expanding the wrong variables.\n   2164             stack_depth = 2\n   2165             magic_arg_s = self.var_expand(line, stack_depth)\n   2166             with self.builtin_trap:\n-> 2167                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = 'param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)'\n   2168             return result\n   2169 \n   2170     def find_line_magic(self, magic_name):\n   2171         \"\"\"Find and return a line magic by name.\n\n...........................................................................\nC:\\Users\\zrankin\\Documents\\github\\poverty_prediction\\notebooks\\<decorator-gen-63> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)', local_ns=None)\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', 'param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)', None), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', 'param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)', None)\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\IPython\\core\\magics\\execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='param_grid = dict(num_leaves=[32,36,40])\\nparams ...=f1_scorer, n_jobs=-1)\\ngrid.fit(train_X, train_y)', local_ns=None)\n   1232                 return\n   1233             end = clock2()\n   1234         else:\n   1235             st = clock2()\n   1236             try:\n-> 1237                 exec(code, glob, local_ns)\n        code = <code object <module> at 0x0000017936AC2B70, file \"<timed exec>\", line 1>\n        glob = {'Counter': <class 'collections.Counter'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HyperoptEstimator': <class 'hpsklearn.estimator.hyperopt_estimator'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', \"import os\\nimport sys\\nimport numpy as np\\nimport p..._ipython().run_line_magic('matplotlib', 'inline')\", '# # Tools for developing code\\n# %load_ext autore...t in sys.path:\\n#     sys.path.append(module_path)', \"train = pd.read_csv('../input/train.csv')\\ntest = pd.read_csv('../input/test.csv')\", 'mapping = {\"yes\": 1, \"no\": 0}\\n\\n# Apply same oper...in[[\\'dependency\\', \\'edjefa\\', \\'edjefe\\']].describe()', \"# Add null Target column to test\\ntest['Target'] ...an\\ndata = train.append(test, ignore_index = True)\", \"# Groupby the household and figure out the numbe...ll have the same target.'.format(len(not_equal)))\", \"# Iterate through each household\\nfor household i...ll have the same target.'.format(len(not_equal)))\", \"# Number of missing in each column\\nmissing = pd....cent', ascending = False).head(10).drop('Target')\", \"# Missing num tablets means you don't have one\\nd...l()\\n\\ndata.loc[data['rez_esc'] > 5, 'rez_esc'] = 5\", \"id_ = ['Id', 'idhogar', 'Target']\\n\\nind_bool = ['...vered every variable: ', len(x) == data.shape[1])\", '# Remove squared variables\\ndata = data.drop(colu...id_ + hh_bool + hh_cont + hh_ordered]\\nheads.shape', '# Create correlation matrix\\ncorr_matrix = heads....lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', \"heads = heads.drop(columns = ['tamhog', 'hogar_t...hhsize-diff'] = heads['tamviv'] - heads['hhsize']\", \"elec = []\\n\\n# Assign values\\nfor i, row in heads.i...ec\\nheads['elec-missing'] = heads['elec'].isnull()\", \"heads = heads.drop(columns = 'area2')\", \"# Wall ordinal variable\\nheads['walls'] = np.argm...nt-per-capita'] = heads['v2a1'] / heads['tamviv']\", 'household_feats = list(heads.columns)', 'ind = data[id_ + ind_bool + ind_ordered]\\nind.shape', '# Create correlation matrix\\ncorr_matrix = ind.co...lumns if any(abs(upper[column]) > 0.95)]\\n\\nto_drop', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4:         dependency       edjefa       edjefe\ncou...0000\nmax       8.000000    21.000000    21.000000, 8:               total   percent\nrez_esc       2758...11      0  0.000000\nparentesco12      0  0.000000, 11: (10307, 99), 12: ['coopele', 'area2', 'tamhog', 'hhsize', 'hogar_total'], 18: (33413, 40), 19: ['female'], 22: (33413, 40), 23: count    33413.000000\nmean         1.214886\nstd ...\nmax          2.000000\nName: tech, dtype: float64, 24:           v18q                           dis    ...1   4     4  0.0      0  \n\n[5 rows x 234 columns], 25:            v18q-min  v18q-max  v18q-sum  v18q-co...       0.0            0  \n\n[5 rows x 234 columns], ...}, 'PermutationImportance': <class 'eli5.sklearn.permutation_importance.PermutationImportance'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFECV': <class 'sklearn.feature_selection.rfe.RFECV'>, ...}\n        local_ns = None\n   1238             except:\n   1239                 self.shell.showtraceback()\n   1240                 return\n   1241             end = clock2()\n\n...........................................................................\nC:\\Users\\zrankin\\Documents\\github\\poverty_prediction\\notebooks\\<timed exec> in <module>()\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=StratifiedKFold(n_splits=5, rand...=make_scorer(f1_score, average=macro), verbose=0), X=array([[0., 0., 1., ..., 0., 0., 0.],\n       [0...., 0., 1.],\n       [0., 0., 1., ..., 0., 0., 0.]]), y=array([4, 3, 3, ..., 4, 4, 4]), groups=None, **fit_params={'early_stopping_rounds': 100, 'eval_set': [(array([[0., 0., 1., ..., 0., 0., 0.],\n       [0...., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of StratifiedKFold(n_splits=5, random_state=1, shuffle=False)>\n        X = array([[0., 0., 1., ..., 0., 0., 0.],\n       [0...., 0., 1.],\n       [0., 0., 1., ..., 0., 0., 0.]])\n        y = array([4, 3, 3, ..., 4, 4, 4])\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Oct  1 08:14:29 2018\nPID: 12832Python 3.6.6: c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\python.exe\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([4, 3, 3, ..., 4, 4, 4]), {'score': make_scorer(f1_score, average=macro)}, array([ 374,  378,  382, ..., 2226, 2227, 2228]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), 0, {'num_leaves': 32}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([4, 3, 3, ..., 4, 4, 4]), {'score': make_scorer(f1_score, average=macro)}, array([ 374,  378,  382, ..., 2226, 2227, 2228]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), 0, {'num_leaves': 32})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), X=memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), y=array([4, 3, 3, ..., 4, 4, 4]), scorer={'score': make_scorer(f1_score, average=macro)}, train=array([ 374,  378,  382, ..., 2226, 2227, 2228]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 459, 462, 464, 465,\n       466, 467, 468, 469]), verbose=0, parameters={'num_leaves': 32}, fit_params={'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method LGBMClassifier.fit of LGBMClassifi...      subsample_for_bin=40000, subsample_freq=0)>\n        X_train = memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]])\n        y_train = array([1, 1, 1, ..., 4, 4, 4])\n        fit_params = {'early_stopping_rounds': 100, 'eval_set': [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], 'verbose': False}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\sklearn.py in fit(self=LGBMClassifier(boosting_type='dart', class_weigh...       subsample_for_bin=40000, subsample_freq=0), X=memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 1.],\n        [0., 0., 1., ..., 0., 0., 0.]]), y=array([1, 1, 1, ..., 4, 4, 4]), sample_weight=None, init_score=None, eval_set=[(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))], eval_names=None, eval_sample_weight=None, eval_class_weight=None, eval_init_score=None, eval_metric='multi_logloss', early_stopping_rounds=100, verbose=False, feature_name='auto', categorical_feature='auto', callbacks=None)\n    678                 eval_set = [eval_set]\n    679             for i, (valid_x, valid_y) in enumerate(eval_set):\n    680                 if valid_x is X and valid_y is y:\n    681                     eval_set[i] = (valid_x, _y)\n    682                 else:\n--> 683                     eval_set[i] = (valid_x, self._le.transform(valid_y))\n        eval_set = [(memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]]), array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))]\n        i = 0\n        valid_x = memmap([[0., 0., 1., ..., 0., 0., 0.],\n        [... 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.]])\n        self._le.transform = <bound method LabelEncoder.transform of LabelEncoder()>\n        valid_y = array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64)\n    684 \n    685         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n    686                                         init_score=init_score, eval_set=eval_set,\n    687                                         eval_names=eval_names,\n\n...........................................................................\nc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py in transform(self=LabelEncoder(), y=array([1, 3, 2, 2, 1, 3, 3, 2, 3, 2, 3, 1, 3, 1,...3, 1, 3, 3, 2, 2, 3, 0, 3, 3, 3, 3], dtype=int64))\n    128         y = column_or_1d(y, warn=True)\n    129 \n    130         classes = np.unique(y)\n    131         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n    132             diff = np.setdiff1d(classes, self.classes_)\n--> 133             raise ValueError(\"y contains new labels: %s\" % str(diff))\n        diff = array([0], dtype=int64)\n    134         return np.searchsorted(self.classes_, y)\n    135 \n    136     def inverse_transform(self, y):\n    137         \"\"\"Transform labels back to original encoding.\n\nValueError: y contains new labels: [0]\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = dict(num_leaves=[32,36,40])\n",
    "params = {'boosting_type': 'dart', \n",
    "                  'colsample_bytree': 0.88, \n",
    "                  'learning_rate': 0.028, \n",
    "                   'min_child_samples': 10, \n",
    "                   'num_leaves': 36, \n",
    "                   'reg_alpha': 0.76, \n",
    "                   'reg_lambda': 0.43, \n",
    "                   'subsample_for_bin': 40000, \n",
    "                   'subsample': 0.54, \n",
    "                   'class_weight': 'balanced'}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(model, param_grid=param_grid, fit_params=fit_params, cv=kfold, scoring=f1_scorer, n_jobs=-1)\n",
    "grid.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', class_weight='balanced',\n",
       "        colsample_bytree=0.88, learning_rate=0.028, max_depth=20,\n",
       "        min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=10000, n_jobs=-1, num_leaves=31,\n",
       "        objective='multiclass', random_state=10, reg_alpha=0.76,\n",
       "        reg_lambda=0.43, silent=True, subsample=0.54,\n",
       "        subsample_for_bin=40000, subsample_freq=0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator, any_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim = svm.SVC()\n",
    "\n",
    "estim.fit(X_train, y_train)\n",
    "\n",
    "print(estim.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "global ITERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ITERATION' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-ae1c8d3c1349>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mITERATION\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ITERATION' is not defined"
     ]
    }
   ],
   "source": [
    "ITERATION += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paredblolad', 'pisomoscer', 'cielorazo', 'lugar1', 'v2a1',\n",
       "       'dependency', 'edjefe', 'edjefa', 'meaneduc', 'overcrowding', 'rooms',\n",
       "       'r4h2', 'r4h3', 'r4m2', 'r4m3', 'r4t1', 'hogar_nin', 'bedrooms',\n",
       "       'qmobilephone', 'walls', 'roof', 'floor', 'walls+roof+floor', 'warning',\n",
       "       'bonus', 'phones-per-capita', 'rooms-per-capita', 'rent-per-capita',\n",
       "       'dis-sum', 'female-std', 'estadocivil7-sum', 'estadocivil7-std',\n",
       "       'parentesco2-std', 'parentesco3-sum', 'instlevel1-sum',\n",
       "       'instlevel2-sum', 'instlevel2-std', 'instlevel3-sum', 'instlevel3-std',\n",
       "       'instlevel4-std', 'instlevel8-sum', 'escolari-min', 'escolari-max',\n",
       "       'escolari-sum', 'escolari-std', 'escolari-range_', 'age-min', 'age-max',\n",
       "       'age-sum', 'age-std', 'age-range_', 'inst-max', 'inst-std',\n",
       "       'inst-range_', 'escolari/age-min', 'escolari/age-max',\n",
       "       'escolari/age-sum', 'escolari/age-std', 'escolari/age-range_',\n",
       "       'inst/age-max', 'inst/age-std', 'inst/age-range_', 'tech-sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
