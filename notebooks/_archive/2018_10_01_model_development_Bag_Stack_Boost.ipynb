{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model developed in (LINK NOTEBOOK) and make Kaggle submission \n",
    "\n",
    "### Issues preventing full incorporation into one pipeline\n",
    "- current structure of `feature_engineer_aggregate_individuals` needs to be run after the other feature engineering, but within a pipeline cannot work on the np array produced by the feature_extraction `FeatureUnion`\n",
    "- betweeen feature engineering and other transformations, want to subset to heads of household (otherwise these transformers will use non-heads in fitting) \n",
    "- if I'm using early stopping, then I need to split data into train and validation sets (which would need to happen after the transformations...)\n",
    "\n",
    "### Why that matters\n",
    "- Hyperopt tuning on entire process\n",
    "- Using `pickle` to save fitted model should it need to be used in production\n",
    "\n",
    "## Things I've learned: \n",
    "- always be precise in the problem you're trying to solve. For example, when figuring out how to best use kfold for xgboost early stopping validation, should I be doing this as a custom estimator, or doing the whole pipeline for the subset of the data? (isn't this just bagging?) \n",
    "\n",
    "# READ\n",
    "- http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/![image.png](attachment:image.png)\n",
    "- https://medium.com/@rrfd/boosting-bagging-and-stacking-ensemble-methods-with-sklearn-and-mlens-a455c0c982de\n",
    "- http://scikit-learn.org/stable/modules/ensemble.html\n",
    "- https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python\n",
    "\n",
    "# Questions\n",
    "- should I be bagging the XGBoost classifier, or stacking multiple? \n",
    "- using `BaggingClassifier` can you implement early stopping with oob? \n",
    "- should you bag AND stack? \n",
    "\n",
    "\n",
    "### Things I'm figuring out\n",
    "- how/if to use early stopping within kfold cross validation (rather than just one validation set). **if I do this please please show your work in a notebook**\n",
    "    - WHAT DO I WANT? I want a pipeline step that runs xgboost with early stopping  on a kfold and uses soft voting to combine, right? \n",
    "    - OR do I want BAGGING? (e.g. `BaggingClassifier`) - the oob could theoretically be used for early stopping, right? \n",
    "    - OR, do I want a regular pipeline that is then fit e.g. 5 times for a kfold with 5 folds, then combine the predictions. This seems slower, but avoids leakage etc and leverages the pipeline tools (e.g. using the different folds for every pipeline step). BUT then it wouldn't actually help do better predictions when pipeline.fit is called (and hence doesn't actually help hyperparameter tuning). ISN'T THIS JUST STACKING (http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/), but does it allow hyperparamter optimization?\n",
    "    - OR is it better to just have the one xgboost classifier in the pipeline, but then do stacking of diverse estimators? https://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/ \n",
    "        - may need a custom pipeline object. I've seen multiple people iterate over kfoldcv and aggregate the predictions (using soft voting). Examples include https://www.kaggle.com/sudosudoohio/stratified-kfold-xgboost-eda-tutorial-0-281 and https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough \n",
    "       - Here's sample code to create a custom estimator: http://danielhnyk.cz/creating-your-own-estimator-scikit-learn/\n",
    "       - The sklearn GradientBoostedClassifier has a built-in `validation_fraction` which seems like could more easily be put into a pipeline, though this notebook makes it seem like it doesn't actually improve test scores? http://scikit-learn.org/dev/auto_examples/ensemble/plot_gradient_boosting_early_stopping.html\n",
    "       - Here's a related discussion on using just the transformers from the pipeline to transform data (which can then be used by the xgboost classifer). https://github.com/scikit-learn/scikit-learn/issues/8414 (note: make sure it hasn't been implemented by sklearn already, i recall that pipeline.transform may call all but estimator inherently)\n",
    "       - Probably unrelated, but here's a lengthy pipeline for titanic data:https://github.com/mratsim/MachineLearning_Kaggle/blob/master/Kaggle%20-%20001%20-%20Titanic%20Survivors/Kaggle-001-Python-MagicalForest.py#L526\n",
    "- how/if to use Hyperopt within kfold cross validation (rather than just one validation set). Granted, this would be much slower. Would doing a proper splitting of the xgboost model help this, given it has to use a set of parameters to train for multiple different cv sets? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Important note: \n",
    "My goal with this repository is **not to get the best Kaggle score**. I know, crazy, right? I'm more interested in learning best practices, such as building one pipeline for the entire model. Most if not all of the leading kernels (such as https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough) may do pipelines for a couple steps but not for the whole model. Indeed, I scored higher when I did all the transformers (including feature selection) once then scored cross validation on just the final estimator (rather than the entire pipeline).  \n",
    "\n",
    "## Lessons\n",
    "- **Feature engineering:** \n",
    "    - Manually using logical features hurt the model, the best way seemed to be making many features and automating feature selection (or using a properly regularized estimator) \n",
    "- **Feature selection:** \n",
    "    - `RFECV` seems to be super sensitive to settings, including the classifier used and hyperparameters therein. Even within cross-validation folds (ie, using the same classifier and hyperparameters), I saw between 13 and 143 features selected. This merits further investigation before using in a final pipeline.\n",
    "    - `SelectFromModel` is much quicker and consistent than `RFECV`, especially given that it exposes an important hyperparameter (`threshold`) for hyperparameter tuning. User note: make sure your feature importances are scaled appropriately for your `threshold`. Oddly, using the final estimator (`BaggedLGBMClassifier`) as the `SelectFromModel` classifier resulted in worse cross-validation scores. \n",
    "- **Early stopping**\n",
    "    - This was key, though it still results in overfitting\n",
    "- **Bagging**\n",
    "    - For simple (and untuned) classification algorithms, bagging had inconsistent results on bias and variance. However, for my implementation of `BaggedLGBMClassifier`, it significantly reduced both bias and variance. Hooray!\n",
    "    - I ended up writing a **custom sklearn estimator**, `BaggedLGBMClassifier`, because I couldn't figure out a way to use bagging *and* early_stopping with the sklearn API (e.g. `BaggingClassifier`). My implementation uses bagging of 5 `LGBMClassifier` estimators whose early_stopping is determined using the unsampled (aka \"out-of-bag\") observations as validation set (since bootstrapped sampling of the data leaves ~37% of the data unsampled). \n",
    "- **Hyperparameter tuning** \n",
    "    - I had success using `Hyperopt` - while it takes a little more setup than `GridSearchCV`, I found it to be very useful. \n",
    "    - *Question*: I'm curious whether using the base implementation of `Hyperopt` can be dangerous. Unlike `GridSearchCV`, it uses only one train/test split of the data to find optimal hyperparameters - couldn't this lead to overfitting? I'm hoping that my use of bagging for the final estimator will avoid or mitigate potential overfitting. \n",
    "    \n",
    "    \n",
    "## Next steps\n",
    "- I haven't yet used sophisticated insights tools for my `BaggedLGBMClassifier`, such as permutation importance, partial dependence plots, and SHAP values. Here is a notebook I've used these tools for a simple Random Forest classifier: https://github.com/zwrankin/chicago_bicycle_share/blob/master/notebooks/2018_09_24_initial_data_exploration_and_models.ipynb\n",
    "- One of the obstacles to implementing these tools is figuring out how to get feature names out of pipelines with feature selection. \n",
    "- Build ensembles with `brew` (https://pypi.org/project/brew/) or `mlens` (https://github.com/flennerhag/mlens)\n",
    "  \n",
    "## Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, RFECV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Tools for developing code\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# Add library to path \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from lib.model import kfold, f1_scorer\n",
    "from lib.model import load_and_process_training_data, load_and_process_test_data\n",
    "from lib.visualization import report_cv_scores\n",
    "from lib.visualization import plot_learning_curve, plot_feature_importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processing training data & tuned hyperparameters\n",
    "(LINK TO NOTEBOOK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_hdf('../models/training.hdf', key='train_X')\n",
    "train_y = pd.read_hdf('../models/training.hdf', key='train_y')\n",
    "val_X = pd.read_hdf('../models/training.hdf', key='val_X')\n",
    "val_y = pd.read_hdf('../models/training.hdf', key='val_y')\n",
    "\n",
    "features = train_X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try bagging of base estimators using `BaggingClassifier`\n",
    "Initial results show that improvement for bias & variance are inconsistent across estimators and depend on subset fractions of samples and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For methods we don't need to do early_stopping\n",
    "X = pd.concat([train_X, val_X]).reset_index().drop('index', axis=1)\n",
    "y = pd.concat([train_y, val_y]).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of: 0.374, std: (+/-) 0.026 [RandomForestClassifier]\n",
      "Mean of: 0.357, std: (+/-) 0.022 [Bagging RandomForestClassifier]\n",
      "\n",
      "Mean of: 0.355, std: (+/-) 0.013 [ExtraTreesClassifier]\n",
      "Mean of: 0.337, std: (+/-) 0.020 [Bagging ExtraTreesClassifier]\n",
      "\n",
      "Mean of: 0.366, std: (+/-) 0.022 [KNeighborsClassifier]\n",
      "Mean of: 0.326, std: (+/-) 0.010 [Bagging KNeighborsClassifier]\n",
      "\n",
      "Mean of: 0.324, std: (+/-) 0.021 [SVC]\n",
      "Mean of: 0.322, std: (+/-) 0.026 [Bagging SVC]\n",
      "\n",
      "Mean of: 0.314, std: (+/-) 0.013 [RidgeClassifier]\n",
      "Mean of: 0.310, std: (+/-) 0.012 [Bagging RidgeClassifier]\n",
      "\n",
      "Wall time: 40.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create classifiers\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "et = ExtraTreesClassifier(random_state=1)\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC(random_state=1)\n",
    "rg = RidgeClassifier(random_state=1)\n",
    "clf_array = [rf, et, knn, svc, rg]\n",
    "for clf in clf_array:\n",
    "    vanilla_scores = cross_val_score(clf, X, y, cv=kfold, scoring=f1_scorer, n_jobs=-1)\n",
    "    bagging_clf = BaggingClassifier(clf, max_samples=0.5, max_features=1.0, n_estimators=10, bootstrap=True, random_state=1)\n",
    "    bagging_scores = cross_val_score(bagging_clf, X, y, cv=kfold, scoring=f1_scorer, n_jobs=-1)\n",
    "    \n",
    "    print(f\"Mean of: {vanilla_scores.mean():.3f}, std: (+/-) {vanilla_scores.std():.3f} [{clf.__class__.__name__}]\")\n",
    "    print(f\"Mean of: {bagging_scores.mean():.3f}, std: (+/-) {bagging_scores.std():.3f} [Bagging {clf.__class__.__name__}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of: 0.374, std: (+/-) 0.026 [RandomForestClassifier]\n",
      "Mean of: 0.361, std: (+/-) 0.013 [Bagging RandomForestClassifier]\n",
      "\n",
      "Mean of: 0.355, std: (+/-) 0.013 [ExtraTreesClassifier]\n",
      "Mean of: 0.344, std: (+/-) 0.015 [Bagging ExtraTreesClassifier]\n",
      "\n",
      "Mean of: 0.366, std: (+/-) 0.022 [KNeighborsClassifier]\n",
      "Mean of: 0.336, std: (+/-) 0.027 [Bagging KNeighborsClassifier]\n",
      "\n",
      "Mean of: 0.324, std: (+/-) 0.021 [SVC]\n",
      "Mean of: 0.342, std: (+/-) 0.018 [Bagging SVC]\n",
      "\n",
      "Mean of: 0.314, std: (+/-) 0.013 [RidgeClassifier]\n",
      "Mean of: 0.320, std: (+/-) 0.007 [Bagging RidgeClassifier]\n",
      "\n",
      "Wall time: 44.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create classifiers\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "et = ExtraTreesClassifier(random_state=1)\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC(random_state=1)\n",
    "rg = RidgeClassifier(random_state=1)\n",
    "clf_array = [rf, et, knn, svc, rg]\n",
    "for clf in clf_array:\n",
    "    vanilla_scores = cross_val_score(clf, X, y, cv=kfold, scoring=f1_scorer, n_jobs=-1)\n",
    "    bagging_clf = BaggingClassifier(clf, max_samples=1.0, max_features=1.0, n_estimators=10, bootstrap=True, random_state=1)\n",
    "    bagging_scores = cross_val_score(bagging_clf, X, y, cv=kfold, scoring=f1_scorer, n_jobs=-1)\n",
    "    \n",
    "    print(f\"Mean of: {vanilla_scores.mean():.3f}, std: (+/-) {vanilla_scores.std():.3f} [{clf.__class__.__name__}]\")\n",
    "    print(f\"Mean of: {bagging_scores.mean():.3f}, std: (+/-) {bagging_scores.std():.3f} [Bagging {clf.__class__.__name__}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually implement bagging (with early stopping) for boosted estimator\n",
    "(I couldn't seem to manage this in the native APIs, but seems like there should be a way)\n",
    "\n",
    "### Conclusion: Using soft voting of 5 identical classifiers using bootstrapped data, the stacked model has lower bias and lower variance than any of the component estimators. Hooray!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart',\n",
       " 'colsample_bytree': 0.5796397953791418,\n",
       " 'learning_rate': 0.08739537002929919,\n",
       " 'min_child_samples': 15,\n",
       " 'num_leaves': 48,\n",
       " 'reg_alpha': 0.4239159481112283,\n",
       " 'reg_lambda': 0.36419362906439723,\n",
       " 'subsample_for_bin': 40000,\n",
       " 'subsample': 0.986210861412967,\n",
       " 'class_weight': 'balanced',\n",
       " 'limit_max_depth': 1,\n",
       " 'max_depth': 22}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_params = pickle.load(open(\"../models/tuned_params.p\", \"rb\"))\n",
    "EARLY_STOPPING_ROUNDS = 10\n",
    "tuned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_and_boost_model(X, y, random_state):\n",
    "    \"\"\"\n",
    "    Fits a gradient boosted model to bootstrapped data, and uses the unsampled (aka \"out-of-bag\") observations\n",
    "    as a validation set for early stopping\n",
    "    Different than sklearn's native BaggingClassifier because it allows early stopping  \n",
    "    \"\"\"\n",
    "    # Note that due to bootstrapping, sample_fraction=1 still leaves ~37% of data in the validation set \n",
    "    X_train, y_train = resample(X, y, n_samples=len(X), replace=True, random_state=random_state) \n",
    "    valid_idx = [i for i in X.index if i not in X_train.index]\n",
    "    X_valid = X.loc[valid_idx]\n",
    "    y_valid = y.loc[valid_idx]\n",
    "    \n",
    "    fit_params = {\"eval_set\": [(X_valid, y_valid)], \n",
    "              \"early_stopping_rounds\": EARLY_STOPPING_ROUNDS, \n",
    "              \"verbose\": False}\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(**tuned_params, objective = 'multiclass', \n",
    "                               n_jobs = -1, n_estimators = 10000,\n",
    "                               random_state = 10)\n",
    " \n",
    "    return clf.fit(X_train, y_train, **fit_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf1 Cross Validation F1 Score = 0.401 with std = 0.0132\n",
      "clf2 Cross Validation F1 Score = 0.4065 with std = 0.0134\n",
      "clf3 Cross Validation F1 Score = 0.4077 with std = 0.0126\n",
      "clf4 Cross Validation F1 Score = 0.4096 with std = 0.0224\n",
      "clf5 Cross Validation F1 Score = 0.3957 with std = 0.0215\n",
      "ENSEMBLE Cross Validation F1 Score = 0.4166 with std = 0.0123\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture --no-stdout\n",
    "\n",
    "def stacked_clfs_predict(clfs, X_test):\n",
    "    probs = np.mean([clf.predict_proba(X_test) for clf in clfs], axis=0)\n",
    "    predictions = pd.DataFrame(probs).idxmax(axis = 1)\n",
    "    return np.array(predictions)  \n",
    "\n",
    "def score_predictions(predictions, y_test, scores):\n",
    "    score = f1_score(y_test, predictions, average = 'macro')\n",
    "    scores.append(score)\n",
    "    return scores\n",
    "    \n",
    "def print_cv_scores(clf_name, scores):\n",
    "    print(f'{clf_name} Cross Validation F1 Score = {round(np.mean(scores), 4)} with std = {round(np.std(scores), 4)}')\n",
    "    \n",
    "scores, clf1_scores, clf2_scores, clf3_scores, clf4_scores, clf5_scores = [[] for _ in range(6)]\n",
    "np.random.seed(0)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "    # print(f'[Fold {i + 1}/5]')\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    clf1 = bag_and_boost_model(X_train, y_train, random_state=i*100 + 1)\n",
    "    clf2 = bag_and_boost_model(X_train, y_train, random_state=i*100 + 2)\n",
    "    clf3 = bag_and_boost_model(X_train, y_train, random_state=i*100 + 3)\n",
    "    clf4 = bag_and_boost_model(X_train, y_train, random_state=i*100 + 4)\n",
    "    clf5 = bag_and_boost_model(X_train, y_train, random_state=i*100 + 5)\n",
    "    \n",
    "    stacked_predictions = stacked_clfs_predict([clf1, clf2, clf3, clf4, clf5], X_test)\n",
    "\n",
    "    scores = score_predictions(stacked_predictions, y_test, scores)\n",
    "    clf1_scores = score_predictions(clf1.predict(X_test), y_test, clf1_scores)\n",
    "    clf2_scores = score_predictions(clf2.predict(X_test), y_test, clf2_scores)\n",
    "    clf3_scores = score_predictions(clf3.predict(X_test), y_test, clf3_scores)\n",
    "    clf4_scores = score_predictions(clf4.predict(X_test), y_test, clf4_scores)\n",
    "    clf5_scores = score_predictions(clf5.predict(X_test), y_test, clf5_scores)\n",
    "\n",
    "for name, scores in zip(['clf1', 'clf2', 'clf3', 'clf4', 'clf5', 'ENSEMBLE'], \n",
    "                        [clf1_scores, clf2_scores, clf3_scores, clf4_scores, clf5_scores, scores]):\n",
    "    print_cv_scores(name, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal - BaggedLGBclassifier Pipeline estimator\n",
    "- fit(X, y)\n",
    "- predict(X)\n",
    "- feature_importances_ (ideally...)\n",
    "\n",
    "## REMEMBER - if it's in a pipeline it'll get an array not a dataframe..\n",
    "## Am I breaking sklearn conventions by having `fit_params` be normal params..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.pipeline import BaggedLGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggedLGBMClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Cross Validation F1 Score = 0.4184 with std = 0.0209\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture --no-stdout\n",
    "\n",
    "scores = []\n",
    "np.random.seed(0)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "    # print(f'[Fold {i + 1}/5]')\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = score_predictions(model.predict(X_test), y_test, scores)\n",
    "\n",
    "print_cv_scores('Model', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a simple pipeline to see if my `BaggedLGBMClassifier` can be used easily in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = load_and_process_training_data()\n",
    "X_data.shape\n",
    "y_data = y_data - 1 #try normalizing to 0 to avoid bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zrankin\\Documents\\github\\poverty_prediction\\lib\\pipeline.py:84: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (y.index == X.index, 'X and y indices do not match')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture --no-stdout\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "                        ('imputer', Imputer(strategy='mean')),\n",
    "                        ('model', BaggedLGBMClassifier()),\n",
    "                        ])\n",
    "\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(pipeline)\n",
    "from lib.model import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-166e0701ae15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \"\"\"\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[0;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    214\u001b[0m                 \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                        **fit_params):\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    434\u001b[0m         scores = parallel(\n\u001b[0;32m    435\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             for train, test in cv.split(X, y))\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture --no-stdout\n",
    "\n",
    "pipeline.fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transformer_pipeline = Pipeline(pipeline.steps[:-1])\n",
    "classifier = Pipeline(pipeline.steps[-1])\n",
    "transformed = transformer_pipeline.fit_transform(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed.shape\n",
    "X_transformed = transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2973, 38)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2973,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "classifier = pipeline.steps[-1][1]\n",
    "classifier.fit(X_transformed, y_data)\n",
    "scores = score_predictions(classifier.predict(X_transformed), y_data, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4315401291050065,\n",
       " 0.36638650684008356,\n",
       " 0.3362760034627622,\n",
       " 0.21534631507079502,\n",
       " 0.39413173981216787]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation F1 Score = 0.3455 with std = 0.0557\n",
      "Wall time: 5min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_score = cross_val_score(pipeline, X_data, y_data, cv=kfold, scoring=f1_scorer, n_jobs=-1)\n",
    "print(f'Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So when I used the transformed data on full pipeline, I get good CV score. \n",
    "When I use the full pipeline on raw data, I get bad CV score (super variable cross-validation scores, some high some low). \n",
    "Here, let's see if I can isolate the issue.\n",
    "Starting with `SelectFromModel` because it's much quicker.\n",
    "- Now trying using RFECV, even though it's slow, but maybe that'll give better results (since that's what's creating the saved transformed data that's giving good and low std cv scores). In fact, it chooses anywhere from 3 to 143 features, and bad scores. \n",
    "- Oddly, using the BaggedLGBMClassifier in `SelectFromModel` gave very poor scores\n",
    "\n",
    "# DOCUMENT THIS STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_predictions(predictions, y_test, scores):\n",
    "    score = f1_score(y_test, predictions, average = 'macro')\n",
    "    scores.append(score)\n",
    "    return scores\n",
    "    \n",
    "def print_cv_scores(clf_name, scores):\n",
    "    print(f'{clf_name} Cross Validation F1 Score = {round(np.mean(scores), 4)} with std = {round(np.std(scores), 4)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = load_and_process_training_data()\n",
    "X_data.shape\n",
    "y_data = y_data - 1 #try normalizing to 0 to avoid bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = pd.read_hdf('../models/training.hdf', key='train_X')\n",
    "# train_y = pd.read_hdf('../models/training.hdf', key='train_y')\n",
    "# val_X = pd.read_hdf('../models/training.hdf', key='val_X')\n",
    "# val_y = pd.read_hdf('../models/training.hdf', key='val_y')\n",
    "\n",
    "# X_data = pd.concat([train_X, val_X]).reset_index().drop('index', axis=1)\n",
    "# y_data = pd.concat([train_y, val_y]).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm always getting the highest \n",
    "folds = [fold for fold in kfold.split(X_data, y_data)]\n",
    "train_index = folds[0][0]\n",
    "test_index = folds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zrankin\\appdata\\local\\continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\zrankin\\Documents\\github\\poverty_prediction\\lib\\pipeline.py:87: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  y = pd.DataFrame(y).reset_index().drop('index', axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2377, 198)\n",
      "(2377, 198)\n",
      "(2379, 198)\n",
      "(2379, 198)\n",
      "(2380, 198)\n",
      "Model Cross Validation F1 Score = 0.3487 with std = 0.0737\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture --no-stdout\n",
    "\n",
    "scores = []\n",
    "np.random.seed(0)\n",
    "from lib.model import pipeline\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X_data, y_data)):\n",
    "    # print(f'[Fold {i + 1}/5]')\n",
    "    #HACK \n",
    "#     train_index = folds[0][0]\n",
    "#     test_index = folds[0][1]\n",
    "    X_train, X_test = X_data.iloc[train_index], X_data.iloc[test_index]\n",
    "    y_train, y_test= y_data.iloc[train_index], y_data.iloc[test_index]\n",
    "\n",
    "    transformer_pipeline = Pipeline(pipeline.steps[:-1])\n",
    "    transformer_pipeline.fit(X_train, y_train)\n",
    "    X_train_t = transformer_pipeline.transform(X_train)\n",
    "    X_test_t = transformer_pipeline.transform(X_test)\n",
    "    print(X_train_t.shape)\n",
    "    \n",
    "    classifier = pipeline.steps[-1][1]\n",
    "    classifier.fit(X_train_t, y_train)\n",
    "    scores = score_predictions(classifier.predict(X_test_t), y_test, scores)\n",
    "    \n",
    "print_cv_scores('Model', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4294427075904234,\n",
       " 0.4046136631095094,\n",
       " 0.4217817676594283,\n",
       " 0.3141564968296868,\n",
       " 0.4166412128993996]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44714384, 0.96890304, 0.36316126, 0.39753349, 0.73868266,\n",
       "       0.44908343, 0.93728436, 0.25723349, 0.38175981, 0.69714162])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random_sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.380 (std: 0.041)\n",
      "Parameters: {'selector__threshold': 0.007}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.379 (std: 0.040)\n",
      "Parameters: {'selector__threshold': 0.01}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.357 (std: 0.067)\n",
      "Parameters: {'selector__threshold': 0.001}\n",
      "\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture --no-stdout\n",
    "\n",
    "# NOTE - selector__threshold range seems to be from \n",
    "# 0.01 (11 features) to 0.001 (177 features), 0.005 gives 96 features\n",
    "param_grid = dict(selector__threshold=[0.001, 0.007, 0.01])\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=kfold, scoring=f1_scorer, n_jobs=-1)\n",
    "grid.fit(X_data, y_data)\n",
    "\n",
    "# print(grid.best_params_)\n",
    "report_cv_scores(grid.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
